{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Nanodegree\n",
    "\n",
    "## Project: Image Captioning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will train your CNN-RNN model.  \n",
    "\n",
    "You are welcome and encouraged to try out many different architectures and hyperparameters when searching for a good model.\n",
    "\n",
    "This does have the potential to make the project quite messy!  Before submitting your project, make sure that you clean up:\n",
    "- the code you write in this notebook.  The notebook should describe how to train a single CNN-RNN architecture, corresponding to your final choice of hyperparameters.  You should structure the notebook so that the reviewer can replicate your results by running the code in this notebook.  \n",
    "- the output of the code cell in **Step 2**.  The output should show the output obtained when training the model from scratch.\n",
    "\n",
    "This notebook **will be graded**.  \n",
    "\n",
    "Feel free to use the links below to navigate the notebook:\n",
    "- [Step 1](#step1): Training Setup\n",
    "- [Step 2](#step2): Train your Model\n",
    "- [Step 3](#step3): (Optional) Validate your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Training Setup\n",
    "\n",
    "In this step of the notebook, you will customize the training of your CNN-RNN model by specifying hyperparameters and setting other options that are important to the training procedure.  The values you set now will be used when training your model in **Step 2** below.\n",
    "\n",
    "You should only amend blocks of code that are preceded by a `TODO` statement.  **Any code blocks that are not preceded by a `TODO` statement should not be modified**.\n",
    "\n",
    "### Task #1\n",
    "\n",
    "Begin by setting the following variables:\n",
    "- `batch_size` - the batch size of each training batch.  It is the number of image-caption pairs used to amend the model weights in each training step. \n",
    "- `vocab_threshold` - the minimum word count threshold.  Note that a larger threshold will result in a smaller vocabulary, whereas a smaller threshold will include rarer words and result in a larger vocabulary.  \n",
    "- `vocab_from_file` - a Boolean that decides whether to load the vocabulary from file. \n",
    "- `embed_size` - the dimensionality of the image and word embeddings.  \n",
    "- `hidden_size` - the number of features in the hidden state of the RNN decoder.  \n",
    "- `num_epochs` - the number of epochs to train the model.  We recommend that you set `num_epochs=3`, but feel free to increase or decrease this number as you wish.  [This paper](https://arxiv.org/pdf/1502.03044.pdf) trained a captioning model on a single state-of-the-art GPU for 3 days, but you'll soon see that you can get reasonable results in a matter of a few hours!  (_But of course, if you want your model to compete with current research, you will have to train for much longer._)\n",
    "- `save_every` - determines how often to save the model weights.  We recommend that you set `save_every=1`, to save the model weights after each epoch.  This way, after the `i`th epoch, the encoder and decoder weights will be saved in the `models/` folder as `encoder-i.pkl` and `decoder-i.pkl`, respectively.\n",
    "- `print_every` - determines how often to print the batch loss to the Jupyter notebook while training.  Note that you **will not** observe a monotonic decrease in the loss function while training - this is perfectly fine and completely expected!  You are encouraged to keep this at its default value of `100` to avoid clogging the notebook, but feel free to change it.\n",
    "- `log_file` - the name of the text file containing - for every step - how the loss and perplexity evolved during training.\n",
    "\n",
    "If you're not sure where to begin to set some of the values above, you can peruse [this paper](https://arxiv.org/pdf/1502.03044.pdf) and [this paper](https://arxiv.org/pdf/1411.4555.pdf) for useful guidance!  **To avoid spending too long on this notebook**, you are encouraged to consult these suggested research papers to obtain a strong initial guess for which hyperparameters are likely to work best.  Then, train a single model, and proceed to the next notebook (**3_Inference.ipynb**).  If you are unhappy with your performance, you can return to this notebook to tweak the hyperparameters (and/or the architecture in **model.py**) and re-train your model.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "**Question:** Describe your CNN-RNN architecture in detail.  With this architecture in mind, how did you select the values of the variables in Task 1?  If you consulted a research paper detailing a successful implementation of an image captioning model, please provide the reference.\n",
    "\n",
    "**Answer:** The architecture consists of an enconder-decoder model. The encoder is Resnet50 CNN with a modified final layer, which is a Dense layer that maps the image features to a 512 dim embedding space, which is the same dimensionality expected by the LSTM cell of the decoder. The decoder is composed of one LSTM Cell followed by a Dense layer. The hidden_size of the RNN is also 512 and the output of the dense layer is of shape (batch_size, capions_length, vocab_size)\n",
    "\n",
    "PS: I followed the architecture suggested in [this paper](https://arxiv.org/pdf/1411.4555.pdf).\n",
    "\n",
    "\n",
    "### (Optional) Task #2\n",
    "\n",
    "Note that we have provided a recommended image transform `transform_train` for pre-processing the training images, but you are welcome (and encouraged!) to modify it as you wish.  When modifying this transform, keep in mind that:\n",
    "- the images in the dataset have varying heights and widths, and \n",
    "- if using a pre-trained model, you must perform the corresponding appropriate normalization.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "**Question:** How did you select the transform in `transform_train`?  If you left the transform at its provided value, why do you think that it is a good choice for your CNN architecture?\n",
    "\n",
    "**Answer:** This transformations are good, because they take into consideration the fact that images come in different sizes and resizes the images to 256x256 pixels. Besides that, They apply random transformations like cropping and filtering that helps the model generalize better. Last but not least, they normalize the pixel intensity values, so that most of them fit in the [-1, 1] interval, which make the training process faster.\n",
    "\n",
    "### Task #3\n",
    "\n",
    "Next, you will specify a Python list containing the learnable parameters of the model.  For instance, if you decide to make all weights in the decoder trainable, but only want to train the weights in the embedding layer of the encoder, then you should set `params` to something like:\n",
    "```\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "```\n",
    "\n",
    "### Question 3\n",
    "\n",
    "**Question:** How did you select the trainable parameters of your architecture?  Why do you think this is a good choice?\n",
    "\n",
    "**Answer:** The trainable parameters in my model were only the last fully conected layer of the encoder and all parameters of the decoder. This is a good approach, because we are using tranfer learning i.e loading a pre-trained CNN that were trained for object detection. Hence there is no need in training its parameters again.\n",
    "\n",
    "### Task #4\n",
    "\n",
    "Finally, you will select an [optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Optimizer).\n",
    "\n",
    "### Question 4\n",
    "\n",
    "**Question:** How did you select the optimizer used to train your model?\n",
    "\n",
    "**Answer:** I decided to use Adam optimizer with the default parameters. It was decided based on experimentation, because training the model with it showed good convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/414113 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 385/414113 [00:00<01:47, 3840.53it/s]\u001b[A\n",
      "  0%|          | 806/414113 [00:00<01:48, 3817.80it/s]\u001b[A\n",
      "  0%|          | 1223/414113 [00:00<01:45, 3915.88it/s]\u001b[A\n",
      "  0%|          | 1659/414113 [00:00<01:42, 4039.29it/s]\u001b[A\n",
      "  1%|          | 2088/414113 [00:00<01:40, 4109.41it/s]\u001b[A\n",
      "  1%|          | 2521/414113 [00:00<01:38, 4172.85it/s]\u001b[A\n",
      "  1%|          | 2944/414113 [00:00<01:38, 4189.20it/s]\u001b[A\n",
      "  1%|          | 3375/414113 [00:00<01:37, 4222.60it/s]\u001b[A\n",
      "  1%|          | 3814/414113 [00:00<01:36, 4271.04it/s]\u001b[A\n",
      "  1%|          | 4234/414113 [00:01<01:36, 4248.34it/s]\u001b[A\n",
      "  1%|          | 4665/414113 [00:01<01:36, 4264.76it/s]\u001b[A\n",
      "  1%|          | 5118/414113 [00:01<01:34, 4340.08it/s]\u001b[A\n",
      "  1%|▏         | 5548/414113 [00:01<01:34, 4322.55it/s]\u001b[A\n",
      "  1%|▏         | 5985/414113 [00:01<01:34, 4336.62it/s]\u001b[A\n",
      "  2%|▏         | 6417/414113 [00:01<01:35, 4274.89it/s]\u001b[A\n",
      "  2%|▏         | 6849/414113 [00:01<01:34, 4288.09it/s]\u001b[A\n",
      "  2%|▏         | 7277/414113 [00:01<01:35, 4273.05it/s]\u001b[A\n",
      "  2%|▏         | 7704/414113 [00:01<01:35, 4261.20it/s]\u001b[A\n",
      "  2%|▏         | 8145/414113 [00:01<01:34, 4304.77it/s]\u001b[A\n",
      "  2%|▏         | 8576/414113 [00:02<01:34, 4287.11it/s]\u001b[A\n",
      "  2%|▏         | 9012/414113 [00:02<01:34, 4307.13it/s]\u001b[A\n",
      "  2%|▏         | 9443/414113 [00:02<01:34, 4264.56it/s]\u001b[A\n",
      "  2%|▏         | 9870/414113 [00:02<01:35, 4244.96it/s]\u001b[A\n",
      "  2%|▏         | 10299/414113 [00:02<01:34, 4256.38it/s]\u001b[A\n",
      "  3%|▎         | 10725/414113 [00:02<01:35, 4242.14it/s]\u001b[A\n",
      "  3%|▎         | 11151/414113 [00:02<01:34, 4247.30it/s]\u001b[A\n",
      "  3%|▎         | 11576/414113 [00:02<01:35, 4229.44it/s]\u001b[A\n",
      "  3%|▎         | 12003/414113 [00:02<01:34, 4239.68it/s]\u001b[A\n",
      "  3%|▎         | 12435/414113 [00:02<01:34, 4263.24it/s]\u001b[A\n",
      "  3%|▎         | 12875/414113 [00:03<01:33, 4300.55it/s]\u001b[A\n",
      "  3%|▎         | 13319/414113 [00:03<01:32, 4339.26it/s]\u001b[A\n",
      "  3%|▎         | 13763/414113 [00:03<01:31, 4366.43it/s]\u001b[A\n",
      "  3%|▎         | 14204/414113 [00:03<01:31, 4376.75it/s]\u001b[A\n",
      "  4%|▎         | 14646/414113 [00:03<01:31, 4388.55it/s]\u001b[A\n",
      "  4%|▎         | 15085/414113 [00:03<01:33, 4281.77it/s]\u001b[A\n",
      "  4%|▍         | 15533/414113 [00:03<01:31, 4338.38it/s]\u001b[A\n",
      "  4%|▍         | 15972/414113 [00:03<01:31, 4353.57it/s]\u001b[A\n",
      "  4%|▍         | 16408/414113 [00:03<01:32, 4301.27it/s]\u001b[A\n",
      "  4%|▍         | 16851/414113 [00:03<01:31, 4337.75it/s]\u001b[A\n",
      "  4%|▍         | 17293/414113 [00:04<01:30, 4361.67it/s]\u001b[A\n",
      "  4%|▍         | 17730/414113 [00:04<01:30, 4362.50it/s]\u001b[A\n",
      "  4%|▍         | 18175/414113 [00:04<01:30, 4385.84it/s]\u001b[A\n",
      "  4%|▍         | 18617/414113 [00:04<01:29, 4395.19it/s]\u001b[A\n",
      "  5%|▍         | 19057/414113 [00:04<01:30, 4378.21it/s]\u001b[A\n",
      "  5%|▍         | 19508/414113 [00:04<01:29, 4416.57it/s]\u001b[A\n",
      "  5%|▍         | 19950/414113 [00:04<01:29, 4396.01it/s]\u001b[A\n",
      "  5%|▍         | 20390/414113 [00:04<01:29, 4394.10it/s]\u001b[A\n",
      "  5%|▌         | 20832/414113 [00:04<01:29, 4400.97it/s]\u001b[A\n",
      "  5%|▌         | 21275/414113 [00:04<01:29, 4406.69it/s]\u001b[A\n",
      "  5%|▌         | 21716/414113 [00:05<01:29, 4385.14it/s]\u001b[A\n",
      "  5%|▌         | 22155/414113 [00:05<01:30, 4352.03it/s]\u001b[A\n",
      "  5%|▌         | 22593/414113 [00:05<01:29, 4357.68it/s]\u001b[A\n",
      "  6%|▌         | 23034/414113 [00:05<01:29, 4370.57it/s]\u001b[A\n",
      "  6%|▌         | 23474/414113 [00:05<01:29, 4378.60it/s]\u001b[A\n",
      "  6%|▌         | 23912/414113 [00:05<01:31, 4255.19it/s]\u001b[A\n",
      "  6%|▌         | 24342/414113 [00:05<01:31, 4267.89it/s]\u001b[A\n",
      "  6%|▌         | 24777/414113 [00:05<01:30, 4291.21it/s]\u001b[A\n",
      "  6%|▌         | 25207/414113 [00:05<01:31, 4272.53it/s]\u001b[A\n",
      "  6%|▌         | 25637/414113 [00:05<01:30, 4279.15it/s]\u001b[A\n",
      "  6%|▋         | 26066/414113 [00:06<01:31, 4249.35it/s]\u001b[A\n",
      "  6%|▋         | 26507/414113 [00:06<01:30, 4293.05it/s]\u001b[A\n",
      "  7%|▋         | 26945/414113 [00:06<01:29, 4315.65it/s]\u001b[A\n",
      "  7%|▋         | 27377/414113 [00:06<01:30, 4295.83it/s]\u001b[A\n",
      "  7%|▋         | 27816/414113 [00:06<01:29, 4320.97it/s]\u001b[A\n",
      "  7%|▋         | 28249/414113 [00:06<01:29, 4305.84it/s]\u001b[A\n",
      "  7%|▋         | 28685/414113 [00:06<01:29, 4321.82it/s]\u001b[A\n",
      "  7%|▋         | 29118/414113 [00:06<01:29, 4312.15it/s]\u001b[A\n",
      "  7%|▋         | 29550/414113 [00:06<01:29, 4288.35it/s]\u001b[A\n",
      "  7%|▋         | 29990/414113 [00:06<01:28, 4318.51it/s]\u001b[A\n",
      "  7%|▋         | 30422/414113 [00:07<01:29, 4285.27it/s]\u001b[A\n",
      "  7%|▋         | 30872/414113 [00:07<01:28, 4345.27it/s]\u001b[A\n",
      "  8%|▊         | 31308/414113 [00:07<01:28, 4349.51it/s]\u001b[A\n",
      "  8%|▊         | 31744/414113 [00:07<01:28, 4333.71it/s]\u001b[A\n",
      "  8%|▊         | 32178/414113 [00:07<01:28, 4331.60it/s]\u001b[A\n",
      "  8%|▊         | 32612/414113 [00:07<01:28, 4319.50it/s]\u001b[A\n",
      "  8%|▊         | 33045/414113 [00:07<01:28, 4313.31it/s]\u001b[A\n",
      "  8%|▊         | 33477/414113 [00:07<01:29, 4276.52it/s]\u001b[A\n",
      "  8%|▊         | 33918/414113 [00:07<01:28, 4314.33it/s]\u001b[A\n",
      "  8%|▊         | 34350/414113 [00:07<01:28, 4298.18it/s]\u001b[A\n",
      "  8%|▊         | 34780/414113 [00:08<01:28, 4281.54it/s]\u001b[A\n",
      "  9%|▊         | 35210/414113 [00:08<01:28, 4285.78it/s]\u001b[A\n",
      "  9%|▊         | 35651/414113 [00:08<01:27, 4321.83it/s]\u001b[A\n",
      "  9%|▊         | 36084/414113 [00:08<01:28, 4273.82it/s]\u001b[A\n",
      "  9%|▉         | 36522/414113 [00:08<01:27, 4303.06it/s]\u001b[A\n",
      "  9%|▉         | 36960/414113 [00:08<01:27, 4325.28it/s]\u001b[A\n",
      "  9%|▉         | 37402/414113 [00:08<01:26, 4351.50it/s]\u001b[A\n",
      "  9%|▉         | 37841/414113 [00:08<01:26, 4360.11it/s]\u001b[A\n",
      "  9%|▉         | 38282/414113 [00:08<01:25, 4372.65it/s]\u001b[A\n",
      "  9%|▉         | 38720/414113 [00:08<01:26, 4331.36it/s]\u001b[A\n",
      "  9%|▉         | 39154/414113 [00:09<01:26, 4331.23it/s]\u001b[A\n",
      " 10%|▉         | 39588/414113 [00:09<01:26, 4315.20it/s]\u001b[A\n",
      " 10%|▉         | 40030/414113 [00:09<01:26, 4344.36it/s]\u001b[A\n",
      " 10%|▉         | 40466/414113 [00:09<01:25, 4347.96it/s]\u001b[A\n",
      " 10%|▉         | 40908/414113 [00:09<01:25, 4367.12it/s]\u001b[A\n",
      " 10%|▉         | 41345/414113 [00:09<01:26, 4322.08it/s]\u001b[A\n",
      " 10%|█         | 41778/414113 [00:09<01:26, 4293.48it/s]\u001b[A\n",
      " 10%|█         | 42212/414113 [00:09<01:26, 4307.16it/s]\u001b[A\n",
      " 10%|█         | 42643/414113 [00:09<01:27, 4267.83it/s]\u001b[A\n",
      " 10%|█         | 43070/414113 [00:10<01:27, 4261.33it/s]\u001b[A\n",
      " 11%|█         | 43503/414113 [00:10<01:26, 4279.21it/s]\u001b[A\n",
      " 11%|█         | 43932/414113 [00:10<01:26, 4267.10it/s]\u001b[A\n",
      " 11%|█         | 44373/414113 [00:10<01:25, 4306.23it/s]\u001b[A\n",
      " 11%|█         | 44808/414113 [00:10<01:25, 4318.22it/s]\u001b[A\n",
      " 11%|█         | 45240/414113 [00:10<01:25, 4314.25it/s]\u001b[A\n",
      " 11%|█         | 45672/414113 [00:10<01:25, 4286.07it/s]\u001b[A\n",
      " 11%|█         | 46117/414113 [00:10<01:24, 4333.21it/s]\u001b[A\n",
      " 11%|█         | 46557/414113 [00:10<01:24, 4349.95it/s]\u001b[A\n",
      " 11%|█▏        | 46993/414113 [00:10<01:25, 4291.63it/s]\u001b[A\n",
      " 11%|█▏        | 47424/414113 [00:11<01:25, 4296.88it/s]\u001b[A\n",
      " 12%|█▏        | 47854/414113 [00:11<01:25, 4287.29it/s]\u001b[A\n",
      " 12%|█▏        | 48283/414113 [00:11<01:26, 4219.27it/s]\u001b[A\n",
      " 12%|█▏        | 48712/414113 [00:11<01:26, 4239.29it/s]\u001b[A\n",
      " 12%|█▏        | 49150/414113 [00:11<01:25, 4277.28it/s]\u001b[A\n",
      " 12%|█▏        | 49591/414113 [00:11<01:24, 4316.02it/s]\u001b[A\n",
      " 12%|█▏        | 50034/414113 [00:11<01:23, 4349.22it/s]\u001b[A\n",
      " 12%|█▏        | 50480/414113 [00:11<01:22, 4381.25it/s]\u001b[A\n",
      " 12%|█▏        | 50919/414113 [00:11<01:23, 4333.31it/s]\u001b[A\n",
      " 12%|█▏        | 51354/414113 [00:11<01:23, 4335.38it/s]\u001b[A\n",
      " 13%|█▎        | 51792/414113 [00:12<01:23, 4345.20it/s]\u001b[A\n",
      " 13%|█▎        | 52235/414113 [00:12<01:22, 4368.76it/s]\u001b[A\n",
      " 13%|█▎        | 52679/414113 [00:12<01:22, 4387.78it/s]\u001b[A\n",
      " 13%|█▎        | 53118/414113 [00:12<01:22, 4382.86it/s]\u001b[A\n",
      " 13%|█▎        | 53561/414113 [00:12<01:22, 4394.17it/s]\u001b[A\n",
      " 13%|█▎        | 54001/414113 [00:12<01:22, 4378.87it/s]\u001b[A\n",
      " 13%|█▎        | 54445/414113 [00:12<01:21, 4396.96it/s]\u001b[A\n",
      " 13%|█▎        | 54885/414113 [00:12<01:21, 4381.91it/s]\u001b[A\n",
      " 13%|█▎        | 55332/414113 [00:12<01:21, 4404.87it/s]\u001b[A\n",
      " 13%|█▎        | 55773/414113 [00:12<01:22, 4318.39it/s]\u001b[A\n",
      " 14%|█▎        | 56219/414113 [00:13<01:22, 4359.51it/s]\u001b[A\n",
      " 14%|█▎        | 56656/414113 [00:13<01:22, 4330.91it/s]\u001b[A\n",
      " 14%|█▍        | 57090/414113 [00:13<01:22, 4321.16it/s]\u001b[A\n",
      " 14%|█▍        | 57529/414113 [00:13<01:22, 4338.49it/s]\u001b[A\n",
      " 14%|█▍        | 57966/414113 [00:13<01:21, 4347.13it/s]\u001b[A\n",
      " 14%|█▍        | 58404/414113 [00:13<01:21, 4355.22it/s]\u001b[A\n",
      " 14%|█▍        | 58842/414113 [00:13<01:21, 4360.43it/s]\u001b[A\n",
      " 14%|█▍        | 59281/414113 [00:13<01:21, 4367.64it/s]\u001b[A\n",
      " 14%|█▍        | 59727/414113 [00:13<01:20, 4394.73it/s]\u001b[A\n",
      " 15%|█▍        | 60167/414113 [00:14<02:21, 2506.34it/s]\u001b[A\n",
      " 15%|█▍        | 60615/414113 [00:14<02:02, 2887.31it/s]\u001b[A\n",
      " 15%|█▍        | 61053/414113 [00:14<01:49, 3216.01it/s]\u001b[A\n",
      " 15%|█▍        | 61495/414113 [00:14<01:40, 3501.96it/s]\u001b[A\n",
      " 15%|█▍        | 61933/414113 [00:14<01:34, 3724.31it/s]\u001b[A\n",
      " 15%|█▌        | 62370/414113 [00:14<01:30, 3896.20it/s]\u001b[A\n",
      " 15%|█▌        | 62808/414113 [00:14<01:27, 4029.51it/s]\u001b[A\n",
      " 15%|█▌        | 63246/414113 [00:14<01:25, 4127.64it/s]\u001b[A\n",
      " 15%|█▌        | 63693/414113 [00:14<01:22, 4222.44it/s]\u001b[A\n",
      " 15%|█▌        | 64133/414113 [00:15<01:21, 4274.04it/s]\u001b[A\n",
      " 16%|█▌        | 64570/414113 [00:15<01:21, 4300.82it/s]\u001b[A\n",
      " 16%|█▌        | 65007/414113 [00:15<01:21, 4301.68it/s]\u001b[A\n",
      " 16%|█▌        | 65447/414113 [00:15<01:20, 4328.37it/s]\u001b[A\n",
      " 16%|█▌        | 65884/414113 [00:15<01:20, 4331.89it/s]\u001b[A\n",
      " 16%|█▌        | 66323/414113 [00:15<01:20, 4346.77it/s]\u001b[A\n",
      " 16%|█▌        | 66760/414113 [00:15<01:23, 4153.51it/s]\u001b[A\n",
      " 16%|█▌        | 67192/414113 [00:15<01:22, 4201.35it/s]\u001b[A\n",
      " 16%|█▋        | 67615/414113 [00:15<01:22, 4207.84it/s]\u001b[A\n",
      " 16%|█▋        | 68046/414113 [00:16<01:21, 4236.27it/s]\u001b[A\n",
      " 17%|█▋        | 68479/414113 [00:16<01:21, 4262.34it/s]\u001b[A\n",
      " 17%|█▋        | 68920/414113 [00:16<01:20, 4303.55it/s]\u001b[A\n",
      " 17%|█▋        | 69359/414113 [00:16<01:19, 4327.61it/s]\u001b[A\n",
      " 17%|█▋        | 69793/414113 [00:16<01:23, 4132.12it/s]\u001b[A\n",
      " 17%|█▋        | 70247/414113 [00:16<01:20, 4246.41it/s]\u001b[A\n",
      " 17%|█▋        | 70698/414113 [00:16<01:19, 4321.26it/s]\u001b[A\n",
      " 17%|█▋        | 71144/414113 [00:16<01:18, 4360.72it/s]\u001b[A\n",
      " 17%|█▋        | 71582/414113 [00:16<01:18, 4352.07it/s]\u001b[A\n",
      " 17%|█▋        | 72031/414113 [00:16<01:17, 4389.66it/s]\u001b[A\n",
      " 18%|█▊        | 72471/414113 [00:17<01:17, 4384.88it/s]\u001b[A\n",
      " 18%|█▊        | 72913/414113 [00:17<01:17, 4394.30it/s]\u001b[A\n",
      " 18%|█▊        | 73353/414113 [00:17<01:17, 4391.70it/s]\u001b[A\n",
      " 18%|█▊        | 73796/414113 [00:17<01:17, 4400.50it/s]\u001b[A\n",
      " 18%|█▊        | 74237/414113 [00:17<01:17, 4398.82it/s]\u001b[A\n",
      " 18%|█▊        | 74678/414113 [00:17<01:17, 4373.08it/s]\u001b[A\n",
      " 18%|█▊        | 75116/414113 [00:17<01:17, 4352.67it/s]\u001b[A\n",
      " 18%|█▊        | 75552/414113 [00:17<01:17, 4350.05it/s]\u001b[A\n",
      " 18%|█▊        | 75991/414113 [00:17<01:17, 4361.10it/s]\u001b[A\n",
      " 18%|█▊        | 76428/414113 [00:17<01:17, 4359.58it/s]\u001b[A\n",
      " 19%|█▊        | 76875/414113 [00:18<01:16, 4389.79it/s]\u001b[A\n",
      " 19%|█▊        | 77319/414113 [00:18<01:16, 4404.40it/s]\u001b[A\n",
      " 19%|█▉        | 77768/414113 [00:18<01:16, 4425.54it/s]\u001b[A\n",
      " 19%|█▉        | 78211/414113 [00:18<01:16, 4407.16it/s]\u001b[A\n",
      " 19%|█▉        | 78659/414113 [00:18<01:15, 4428.24it/s]\u001b[A\n",
      " 19%|█▉        | 79102/414113 [00:18<01:16, 4399.81it/s]\u001b[A\n",
      " 19%|█▉        | 79544/414113 [00:18<01:15, 4403.14it/s]\u001b[A\n",
      " 19%|█▉        | 79985/414113 [00:18<01:19, 4223.20it/s]\u001b[A\n",
      " 19%|█▉        | 80423/414113 [00:18<01:18, 4267.29it/s]\u001b[A\n",
      " 20%|█▉        | 80867/414113 [00:18<01:17, 4316.29it/s]\u001b[A\n",
      " 20%|█▉        | 81315/414113 [00:19<01:16, 4362.17it/s]\u001b[A\n",
      " 20%|█▉        | 81753/414113 [00:19<01:16, 4366.44it/s]\u001b[A\n",
      " 20%|█▉        | 82198/414113 [00:19<01:15, 4391.07it/s]\u001b[A\n",
      " 20%|█▉        | 82647/414113 [00:19<01:15, 4417.70it/s]\u001b[A\n",
      " 20%|██        | 83090/414113 [00:19<01:15, 4410.51it/s]\u001b[A\n",
      " 20%|██        | 83537/414113 [00:19<01:14, 4425.81it/s]\u001b[A\n",
      " 20%|██        | 83980/414113 [00:19<01:15, 4399.78it/s]\u001b[A\n",
      " 20%|██        | 84425/414113 [00:19<01:14, 4414.68it/s]\u001b[A\n",
      " 20%|██        | 84867/414113 [00:19<01:15, 4342.11it/s]\u001b[A\n",
      " 21%|██        | 85308/414113 [00:19<01:15, 4361.22it/s]\u001b[A\n",
      " 21%|██        | 85747/414113 [00:20<01:15, 4368.41it/s]\u001b[A\n",
      " 21%|██        | 86185/414113 [00:20<01:15, 4364.26it/s]\u001b[A\n",
      " 21%|██        | 86638/414113 [00:20<01:14, 4412.63it/s]\u001b[A\n",
      " 21%|██        | 87083/414113 [00:20<01:13, 4421.83it/s]\u001b[A\n",
      " 21%|██        | 87526/414113 [00:20<01:14, 4395.26it/s]\u001b[A\n",
      " 21%|██        | 87977/414113 [00:20<01:13, 4426.79it/s]\u001b[A\n",
      " 21%|██▏       | 88427/414113 [00:20<01:13, 4447.17it/s]\u001b[A\n",
      " 21%|██▏       | 88872/414113 [00:20<01:13, 4427.14it/s]\u001b[A\n",
      " 22%|██▏       | 89323/414113 [00:20<01:12, 4450.03it/s]\u001b[A\n",
      " 22%|██▏       | 89769/414113 [00:20<01:13, 4407.78it/s]\u001b[A\n",
      " 22%|██▏       | 90210/414113 [00:21<01:13, 4384.60it/s]\u001b[A\n",
      " 22%|██▏       | 90650/414113 [00:21<01:13, 4388.74it/s]\u001b[A\n",
      " 22%|██▏       | 91089/414113 [00:21<01:13, 4388.61it/s]\u001b[A\n",
      " 22%|██▏       | 91528/414113 [00:21<01:13, 4387.63it/s]\u001b[A\n",
      " 22%|██▏       | 91970/414113 [00:21<01:13, 4396.58it/s]\u001b[A\n",
      " 22%|██▏       | 92410/414113 [00:21<01:13, 4396.26it/s]\u001b[A\n",
      " 22%|██▏       | 92856/414113 [00:21<01:12, 4414.89it/s]\u001b[A\n",
      " 23%|██▎       | 93298/414113 [00:21<01:12, 4397.86it/s]\u001b[A\n",
      " 23%|██▎       | 93738/414113 [00:21<01:13, 4373.20it/s]\u001b[A\n",
      " 23%|██▎       | 94184/414113 [00:21<01:12, 4397.47it/s]\u001b[A\n",
      " 23%|██▎       | 94624/414113 [00:22<01:12, 4390.40it/s]\u001b[A\n",
      " 23%|██▎       | 95064/414113 [00:22<01:12, 4391.63it/s]\u001b[A\n",
      " 23%|██▎       | 95504/414113 [00:22<01:12, 4386.59it/s]\u001b[A\n",
      " 23%|██▎       | 95949/414113 [00:22<01:12, 4403.86it/s]\u001b[A\n",
      " 23%|██▎       | 96390/414113 [00:22<01:12, 4402.85it/s]\u001b[A\n",
      " 23%|██▎       | 96831/414113 [00:22<01:12, 4386.17it/s]\u001b[A\n",
      " 23%|██▎       | 97276/414113 [00:22<01:11, 4405.04it/s]\u001b[A\n",
      " 24%|██▎       | 97717/414113 [00:22<01:11, 4397.54it/s]\u001b[A\n",
      " 24%|██▎       | 98157/414113 [00:22<01:11, 4393.85it/s]\u001b[A\n",
      " 24%|██▍       | 98597/414113 [00:22<01:12, 4370.67it/s]\u001b[A\n",
      " 24%|██▍       | 99035/414113 [00:23<01:12, 4362.30it/s]\u001b[A\n",
      " 24%|██▍       | 99472/414113 [00:23<01:12, 4345.93it/s]\u001b[A\n",
      " 24%|██▍       | 99907/414113 [00:23<01:12, 4338.76it/s]\u001b[A\n",
      " 24%|██▍       | 100349/414113 [00:23<01:11, 4360.72it/s]\u001b[A\n",
      " 24%|██▍       | 100787/414113 [00:23<01:11, 4365.91it/s]\u001b[A\n",
      " 24%|██▍       | 101224/414113 [00:23<01:15, 4144.64it/s]\u001b[A\n",
      " 25%|██▍       | 101649/414113 [00:23<01:14, 4175.48it/s]\u001b[A\n",
      " 25%|██▍       | 102077/414113 [00:23<01:14, 4205.26it/s]\u001b[A\n",
      " 25%|██▍       | 102508/414113 [00:23<01:13, 4234.10it/s]\u001b[A\n",
      " 25%|██▍       | 102947/414113 [00:24<01:12, 4278.98it/s]\u001b[A\n",
      " 25%|██▍       | 103399/414113 [00:24<01:11, 4346.12it/s]\u001b[A\n",
      " 25%|██▌       | 103835/414113 [00:24<01:11, 4346.15it/s]\u001b[A\n",
      " 25%|██▌       | 104288/414113 [00:24<01:10, 4397.52it/s]\u001b[A\n",
      " 25%|██▌       | 104733/414113 [00:24<01:10, 4412.02it/s]\u001b[A\n",
      " 25%|██▌       | 105175/414113 [00:24<01:10, 4388.02it/s]\u001b[A\n",
      " 26%|██▌       | 105615/414113 [00:24<01:10, 4355.91it/s]\u001b[A\n",
      " 26%|██▌       | 106068/414113 [00:24<01:09, 4404.15it/s]\u001b[A\n",
      " 26%|██▌       | 106509/414113 [00:24<01:10, 4377.06it/s]\u001b[A\n",
      " 26%|██▌       | 106952/414113 [00:24<01:09, 4391.93it/s]\u001b[A\n",
      " 26%|██▌       | 107401/414113 [00:25<01:09, 4419.09it/s]\u001b[A\n",
      " 26%|██▌       | 107844/414113 [00:25<01:10, 4368.96it/s]\u001b[A\n",
      " 26%|██▌       | 108284/414113 [00:25<01:09, 4376.82it/s]\u001b[A\n",
      " 26%|██▋       | 108724/414113 [00:25<01:09, 4381.96it/s]\u001b[A\n",
      " 26%|██▋       | 109163/414113 [00:25<01:09, 4375.35it/s]\u001b[A\n",
      " 26%|██▋       | 109606/414113 [00:25<01:09, 4389.92it/s]\u001b[A\n",
      " 27%|██▋       | 110046/414113 [00:25<01:09, 4363.76it/s]\u001b[A\n",
      " 27%|██▋       | 110486/414113 [00:25<01:09, 4371.81it/s]\u001b[A\n",
      " 27%|██▋       | 110931/414113 [00:25<01:08, 4393.96it/s]\u001b[A\n",
      " 27%|██▋       | 111371/414113 [00:25<01:09, 4379.93it/s]\u001b[A\n",
      " 27%|██▋       | 111813/414113 [00:26<01:08, 4390.58it/s]\u001b[A\n",
      " 27%|██▋       | 112260/414113 [00:26<01:08, 4410.98it/s]\u001b[A\n",
      " 27%|██▋       | 112708/414113 [00:26<01:08, 4429.90it/s]\u001b[A\n",
      " 27%|██▋       | 113166/414113 [00:26<01:07, 4470.89it/s]\u001b[A\n",
      " 27%|██▋       | 113614/414113 [00:26<01:07, 4452.99it/s]\u001b[A\n",
      " 28%|██▊       | 114060/414113 [00:26<01:07, 4440.11it/s]\u001b[A\n",
      " 28%|██▊       | 114505/414113 [00:26<01:07, 4409.76it/s]\u001b[A\n",
      " 28%|██▊       | 114956/414113 [00:26<01:07, 4436.57it/s]\u001b[A\n",
      " 28%|██▊       | 115400/414113 [00:26<01:08, 4368.46it/s]\u001b[A\n",
      " 28%|██▊       | 115852/414113 [00:26<01:07, 4410.10it/s]\u001b[A\n",
      " 28%|██▊       | 116297/414113 [00:27<01:07, 4419.95it/s]\u001b[A\n",
      " 28%|██▊       | 116743/414113 [00:27<01:07, 4430.42it/s]\u001b[A\n",
      " 28%|██▊       | 117188/414113 [00:27<01:06, 4435.32it/s]\u001b[A\n",
      " 28%|██▊       | 117641/414113 [00:27<01:06, 4461.11it/s]\u001b[A\n",
      " 29%|██▊       | 118088/414113 [00:27<01:06, 4431.65it/s]\u001b[A\n",
      " 29%|██▊       | 118532/414113 [00:27<01:06, 4428.33it/s]\u001b[A\n",
      " 29%|██▊       | 118975/414113 [00:27<01:07, 4399.98it/s]\u001b[A\n",
      " 29%|██▉       | 119419/414113 [00:27<01:06, 4407.09it/s]\u001b[A\n",
      " 29%|██▉       | 119873/414113 [00:27<01:06, 4443.37it/s]\u001b[A\n",
      " 29%|██▉       | 120318/414113 [00:27<01:06, 4424.33it/s]\u001b[A\n",
      " 29%|██▉       | 120761/414113 [00:28<01:06, 4423.79it/s]\u001b[A\n",
      " 29%|██▉       | 121217/414113 [00:28<01:05, 4462.37it/s]\u001b[A\n",
      " 29%|██▉       | 121664/414113 [00:28<01:05, 4439.36it/s]\u001b[A\n",
      " 29%|██▉       | 122109/414113 [00:28<01:05, 4426.71it/s]\u001b[A\n",
      " 30%|██▉       | 122552/414113 [00:28<01:06, 4402.93it/s]\u001b[A\n",
      " 30%|██▉       | 122993/414113 [00:28<01:06, 4389.80it/s]\u001b[A\n",
      " 30%|██▉       | 123433/414113 [00:28<01:06, 4374.85it/s]\u001b[A\n",
      " 30%|██▉       | 123876/414113 [00:28<01:06, 4390.39it/s]\u001b[A\n",
      " 30%|███       | 124317/414113 [00:28<01:05, 4393.17it/s]\u001b[A\n",
      " 30%|███       | 124757/414113 [00:28<01:06, 4382.65it/s]\u001b[A\n",
      " 30%|███       | 125214/414113 [00:29<01:05, 4436.83it/s]\u001b[A\n",
      " 30%|███       | 125658/414113 [00:29<01:05, 4407.69it/s]\u001b[A\n",
      " 30%|███       | 126107/414113 [00:29<01:04, 4431.05it/s]\u001b[A\n",
      " 31%|███       | 126551/414113 [00:29<01:05, 4422.84it/s]\u001b[A\n",
      " 31%|███       | 127004/414113 [00:29<01:04, 4452.18it/s]\u001b[A\n",
      " 31%|███       | 127450/414113 [00:29<01:04, 4425.11it/s]\u001b[A\n",
      " 31%|███       | 127893/414113 [00:29<01:05, 4403.26it/s]\u001b[A\n",
      " 31%|███       | 128343/414113 [00:29<01:04, 4429.93it/s]\u001b[A\n",
      " 31%|███       | 128791/414113 [00:29<01:04, 4444.63it/s]\u001b[A\n",
      " 31%|███       | 129236/414113 [00:29<01:04, 4445.91it/s]\u001b[A\n",
      " 31%|███▏      | 129696/414113 [00:30<01:03, 4489.18it/s]\u001b[A\n",
      " 31%|███▏      | 130148/414113 [00:30<01:03, 4496.47it/s]\u001b[A\n",
      " 32%|███▏      | 130598/414113 [00:30<01:03, 4465.75it/s]\u001b[A\n",
      " 32%|███▏      | 131045/414113 [00:30<01:03, 4431.52it/s]\u001b[A\n",
      " 32%|███▏      | 131490/414113 [00:30<01:03, 4434.70it/s]\u001b[A\n",
      " 32%|███▏      | 131934/414113 [00:30<01:03, 4434.48it/s]\u001b[A\n",
      " 32%|███▏      | 132378/414113 [00:30<01:04, 4398.43it/s]\u001b[A\n",
      " 32%|███▏      | 132818/414113 [00:30<01:03, 4396.23it/s]\u001b[A\n",
      " 32%|███▏      | 133261/414113 [00:30<01:03, 4404.25it/s]\u001b[A\n",
      " 32%|███▏      | 133712/414113 [00:30<01:03, 4432.23it/s]\u001b[A\n",
      " 32%|███▏      | 134156/414113 [00:31<01:03, 4423.12it/s]\u001b[A\n",
      " 33%|███▎      | 134599/414113 [00:31<01:03, 4401.17it/s]\u001b[A\n",
      " 33%|███▎      | 135048/414113 [00:31<01:03, 4427.17it/s]\u001b[A\n",
      " 33%|███▎      | 135491/414113 [00:31<01:04, 4322.32it/s]\u001b[A\n",
      " 33%|███▎      | 135941/414113 [00:31<01:03, 4372.74it/s]\u001b[A\n",
      " 33%|███▎      | 136384/414113 [00:31<01:03, 4387.62it/s]\u001b[A\n",
      " 33%|███▎      | 136824/414113 [00:31<01:03, 4358.44it/s]\u001b[A\n",
      " 33%|███▎      | 137266/414113 [00:31<01:03, 4374.99it/s]\u001b[A\n",
      " 33%|███▎      | 137704/414113 [00:31<01:03, 4371.42it/s]\u001b[A\n",
      " 33%|███▎      | 138142/414113 [00:31<01:03, 4354.78it/s]\u001b[A\n",
      " 33%|███▎      | 138588/414113 [00:32<01:02, 4385.58it/s]\u001b[A\n",
      " 34%|███▎      | 139031/414113 [00:32<01:02, 4396.66it/s]\u001b[A\n",
      " 34%|███▎      | 139478/414113 [00:32<01:02, 4417.41it/s]\u001b[A\n",
      " 34%|███▍      | 139921/414113 [00:32<01:02, 4417.98it/s]\u001b[A\n",
      " 34%|███▍      | 140363/414113 [00:32<01:02, 4397.98it/s]\u001b[A\n",
      " 34%|███▍      | 140810/414113 [00:32<01:01, 4416.39it/s]\u001b[A\n",
      " 34%|███▍      | 141252/414113 [00:32<01:02, 4389.37it/s]\u001b[A\n",
      " 34%|███▍      | 141692/414113 [00:32<01:02, 4381.73it/s]\u001b[A\n",
      " 34%|███▍      | 142138/414113 [00:32<01:01, 4404.82it/s]\u001b[A\n",
      " 34%|███▍      | 142579/414113 [00:33<01:05, 4161.78it/s]\u001b[A\n",
      " 35%|███▍      | 143007/414113 [00:33<01:04, 4194.17it/s]\u001b[A\n",
      " 35%|███▍      | 143448/414113 [00:33<01:03, 4255.91it/s]\u001b[A\n",
      " 35%|███▍      | 143885/414113 [00:33<01:03, 4286.74it/s]\u001b[A\n",
      " 35%|███▍      | 144325/414113 [00:33<01:02, 4318.83it/s]\u001b[A\n",
      " 35%|███▍      | 144763/414113 [00:33<01:02, 4335.02it/s]\u001b[A\n",
      " 35%|███▌      | 145198/414113 [00:33<01:02, 4323.83it/s]\u001b[A\n",
      " 35%|███▌      | 145648/414113 [00:33<01:01, 4372.73it/s]\u001b[A\n",
      " 35%|███▌      | 146086/414113 [00:33<01:01, 4371.09it/s]\u001b[A\n",
      " 35%|███▌      | 146528/414113 [00:33<01:01, 4384.18it/s]\u001b[A\n",
      " 35%|███▌      | 146975/414113 [00:34<01:00, 4408.31it/s]\u001b[A\n",
      " 36%|███▌      | 147426/414113 [00:34<01:00, 4436.05it/s]\u001b[A\n",
      " 36%|███▌      | 147870/414113 [00:34<01:00, 4425.25it/s]\u001b[A\n",
      " 36%|███▌      | 148317/414113 [00:34<00:59, 4437.30it/s]\u001b[A\n",
      " 36%|███▌      | 148765/414113 [00:34<00:59, 4449.47it/s]\u001b[A\n",
      " 36%|███▌      | 149211/414113 [00:34<00:59, 4450.94it/s]\u001b[A\n",
      " 36%|███▌      | 149661/414113 [00:34<00:59, 4463.94it/s]\u001b[A\n",
      " 36%|███▌      | 150108/414113 [00:34<00:59, 4446.65it/s]\u001b[A\n",
      " 36%|███▋      | 150554/414113 [00:34<00:59, 4449.93it/s]\u001b[A\n",
      " 36%|███▋      | 151000/414113 [00:34<00:59, 4418.19it/s]\u001b[A\n",
      " 37%|███▋      | 151442/414113 [00:35<00:59, 4407.69it/s]\u001b[A\n",
      " 37%|███▋      | 151889/414113 [00:35<00:59, 4424.34it/s]\u001b[A\n",
      " 37%|███▋      | 152336/414113 [00:35<00:59, 4435.44it/s]\u001b[A\n",
      " 37%|███▋      | 152789/414113 [00:35<00:58, 4462.45it/s]\u001b[A\n",
      " 37%|███▋      | 153236/414113 [00:35<00:58, 4438.95it/s]\u001b[A\n",
      " 37%|███▋      | 153694/414113 [00:35<00:58, 4478.07it/s]\u001b[A\n",
      " 37%|███▋      | 154144/414113 [00:35<00:58, 4481.30it/s]\u001b[A\n",
      " 37%|███▋      | 154593/414113 [00:35<00:58, 4458.03it/s]\u001b[A\n",
      " 37%|███▋      | 155039/414113 [00:35<00:58, 4454.53it/s]\u001b[A\n",
      " 38%|███▊      | 155485/414113 [00:35<00:58, 4421.19it/s]\u001b[A\n",
      " 38%|███▊      | 155929/414113 [00:36<00:58, 4426.16it/s]\u001b[A\n",
      " 38%|███▊      | 156372/414113 [00:36<00:58, 4419.28it/s]\u001b[A\n",
      " 38%|███▊      | 156826/414113 [00:36<00:57, 4452.84it/s]\u001b[A\n",
      " 38%|███▊      | 157273/414113 [00:36<00:57, 4457.91it/s]\u001b[A\n",
      " 38%|███▊      | 157719/414113 [00:36<00:57, 4433.38it/s]\u001b[A\n",
      " 38%|███▊      | 158173/414113 [00:36<00:57, 4462.78it/s]\u001b[A\n",
      " 38%|███▊      | 158620/414113 [00:36<00:57, 4454.73it/s]\u001b[A\n",
      " 38%|███▊      | 159076/414113 [00:36<00:56, 4484.61it/s]\u001b[A\n",
      " 39%|███▊      | 159526/414113 [00:36<00:56, 4488.28it/s]\u001b[A\n",
      " 39%|███▊      | 159979/414113 [00:36<00:56, 4500.41it/s]\u001b[A\n",
      " 39%|███▊      | 160430/414113 [00:37<00:56, 4476.92it/s]\u001b[A\n",
      " 39%|███▉      | 160878/414113 [00:37<00:56, 4457.47it/s]\u001b[A\n",
      " 39%|███▉      | 161333/414113 [00:37<00:56, 4482.67it/s]\u001b[A\n",
      " 39%|███▉      | 161786/414113 [00:37<00:56, 4496.33it/s]\u001b[A\n",
      " 39%|███▉      | 162239/414113 [00:37<00:55, 4503.64it/s]\u001b[A\n",
      " 39%|███▉      | 162690/414113 [00:37<00:55, 4504.86it/s]\u001b[A\n",
      " 39%|███▉      | 163141/414113 [00:37<00:55, 4503.87it/s]\u001b[A\n",
      " 40%|███▉      | 163596/414113 [00:37<00:55, 4514.32it/s]\u001b[A\n",
      " 40%|███▉      | 164048/414113 [00:37<00:55, 4491.00it/s]\u001b[A\n",
      " 40%|███▉      | 164498/414113 [00:37<00:57, 4311.05it/s]\u001b[A\n",
      " 40%|███▉      | 164935/414113 [00:38<00:57, 4328.34it/s]\u001b[A\n",
      " 40%|███▉      | 165372/414113 [00:38<00:57, 4338.81it/s]\u001b[A\n",
      " 40%|████      | 165807/414113 [00:38<00:57, 4334.79it/s]\u001b[A\n",
      " 40%|████      | 166242/414113 [00:38<00:57, 4316.81it/s]\u001b[A\n",
      " 40%|████      | 166675/414113 [00:38<00:57, 4291.92it/s]\u001b[A\n",
      " 40%|████      | 167115/414113 [00:38<00:57, 4323.65it/s]\u001b[A\n",
      " 40%|████      | 167560/414113 [00:38<00:56, 4359.85it/s]\u001b[A\n",
      " 41%|████      | 167997/414113 [00:38<00:56, 4361.03it/s]\u001b[A\n",
      " 41%|████      | 168434/414113 [00:38<00:56, 4362.41it/s]\u001b[A\n",
      " 41%|████      | 168873/414113 [00:38<00:56, 4366.19it/s]\u001b[A\n",
      " 41%|████      | 169310/414113 [00:39<00:56, 4366.48it/s]\u001b[A\n",
      " 41%|████      | 169747/414113 [00:39<00:56, 4355.42it/s]\u001b[A\n",
      " 41%|████      | 170183/414113 [00:39<00:56, 4337.83it/s]\u001b[A\n",
      " 41%|████      | 170620/414113 [00:39<00:56, 4346.68it/s]\u001b[A\n",
      " 41%|████▏     | 171065/414113 [00:39<00:55, 4375.19it/s]\u001b[A\n",
      " 41%|████▏     | 171503/414113 [00:39<00:55, 4362.47it/s]\u001b[A\n",
      " 42%|████▏     | 171947/414113 [00:39<00:55, 4382.84it/s]\u001b[A\n",
      " 42%|████▏     | 172392/414113 [00:39<00:54, 4402.23it/s]\u001b[A\n",
      " 42%|████▏     | 172833/414113 [00:39<00:54, 4404.11it/s]\u001b[A\n",
      " 42%|████▏     | 173274/414113 [00:39<00:55, 4377.56it/s]\u001b[A\n",
      " 42%|████▏     | 173712/414113 [00:40<00:55, 4339.93it/s]\u001b[A\n",
      " 42%|████▏     | 174154/414113 [00:40<00:55, 4361.07it/s]\u001b[A\n",
      " 42%|████▏     | 174591/414113 [00:40<00:55, 4351.09it/s]\u001b[A\n",
      " 42%|████▏     | 175027/414113 [00:40<00:55, 4306.94it/s]\u001b[A\n",
      " 42%|████▏     | 175458/414113 [00:40<00:55, 4305.79it/s]\u001b[A\n",
      " 42%|████▏     | 175901/414113 [00:40<00:54, 4341.13it/s]\u001b[A\n",
      " 43%|████▎     | 176336/414113 [00:40<00:55, 4315.91it/s]\u001b[A\n",
      " 43%|████▎     | 176780/414113 [00:40<00:54, 4350.85it/s]\u001b[A\n",
      " 43%|████▎     | 177216/414113 [00:41<01:40, 2350.24it/s]\u001b[A\n",
      " 43%|████▎     | 177651/414113 [00:41<01:26, 2725.96it/s]\u001b[A\n",
      " 43%|████▎     | 178097/414113 [00:41<01:16, 3084.50it/s]\u001b[A\n",
      " 43%|████▎     | 178535/414113 [00:41<01:09, 3382.66it/s]\u001b[A\n",
      " 43%|████▎     | 178973/414113 [00:41<01:04, 3629.86it/s]\u001b[A\n",
      " 43%|████▎     | 179409/414113 [00:41<01:01, 3820.46it/s]\u001b[A\n",
      " 43%|████▎     | 179837/414113 [00:41<00:59, 3947.27it/s]\u001b[A\n",
      " 44%|████▎     | 180273/414113 [00:41<00:57, 4062.45it/s]\u001b[A\n",
      " 44%|████▎     | 180705/414113 [00:41<00:56, 4136.00it/s]\u001b[A\n",
      " 44%|████▎     | 181139/414113 [00:42<00:55, 4193.16it/s]\u001b[A\n",
      " 44%|████▍     | 181583/414113 [00:42<00:54, 4261.51it/s]\u001b[A\n",
      " 44%|████▍     | 182018/414113 [00:42<00:54, 4286.39it/s]\u001b[A\n",
      " 44%|████▍     | 182458/414113 [00:42<00:53, 4317.70it/s]\u001b[A\n",
      " 44%|████▍     | 182894/414113 [00:42<00:53, 4323.40it/s]\u001b[A\n",
      " 44%|████▍     | 183330/414113 [00:42<00:53, 4327.51it/s]\u001b[A\n",
      " 44%|████▍     | 183765/414113 [00:42<00:53, 4307.00it/s]\u001b[A\n",
      " 44%|████▍     | 184205/414113 [00:42<00:53, 4331.30it/s]\u001b[A\n",
      " 45%|████▍     | 184640/414113 [00:42<00:53, 4326.90it/s]\u001b[A\n",
      " 45%|████▍     | 185074/414113 [00:42<00:53, 4299.57it/s]\u001b[A\n",
      " 45%|████▍     | 185506/414113 [00:43<00:53, 4304.89it/s]\u001b[A\n",
      " 45%|████▍     | 185937/414113 [00:43<00:52, 4305.75it/s]\u001b[A\n",
      " 45%|████▌     | 186380/414113 [00:43<00:52, 4341.93it/s]\u001b[A\n",
      " 45%|████▌     | 186827/414113 [00:43<00:51, 4377.04it/s]\u001b[A\n",
      " 45%|████▌     | 187265/414113 [00:43<00:52, 4358.77it/s]\u001b[A\n",
      " 45%|████▌     | 187704/414113 [00:43<00:51, 4365.39it/s]\u001b[A\n",
      " 45%|████▌     | 188141/414113 [00:43<00:53, 4230.35it/s]\u001b[A\n",
      " 46%|████▌     | 188566/414113 [00:43<00:54, 4131.77it/s]\u001b[A\n",
      " 46%|████▌     | 189000/414113 [00:43<00:53, 4190.00it/s]\u001b[A\n",
      " 46%|████▌     | 189438/414113 [00:43<00:52, 4243.57it/s]\u001b[A\n",
      " 46%|████▌     | 189881/414113 [00:44<00:52, 4295.96it/s]\u001b[A\n",
      " 46%|████▌     | 190328/414113 [00:44<00:51, 4345.10it/s]\u001b[A\n",
      " 46%|████▌     | 190777/414113 [00:44<00:50, 4387.49it/s]\u001b[A\n",
      " 46%|████▌     | 191221/414113 [00:44<00:50, 4401.41it/s]\u001b[A\n",
      " 46%|████▋     | 191662/414113 [00:44<00:51, 4346.30it/s]\u001b[A\n",
      " 46%|████▋     | 192105/414113 [00:44<00:50, 4369.96it/s]\u001b[A\n",
      " 46%|████▋     | 192543/414113 [00:44<00:50, 4367.60it/s]\u001b[A\n",
      " 47%|████▋     | 192993/414113 [00:44<00:50, 4405.30it/s]\u001b[A\n",
      " 47%|████▋     | 193434/414113 [00:44<00:50, 4388.74it/s]\u001b[A\n",
      " 47%|████▋     | 193874/414113 [00:45<00:52, 4167.83it/s]\u001b[A\n",
      " 47%|████▋     | 194320/414113 [00:45<00:51, 4249.33it/s]\u001b[A\n",
      " 47%|████▋     | 194761/414113 [00:45<00:51, 4294.10it/s]\u001b[A\n",
      " 47%|████▋     | 195206/414113 [00:45<00:50, 4338.26it/s]\u001b[A\n",
      " 47%|████▋     | 195642/414113 [00:45<00:51, 4258.63it/s]\u001b[A\n",
      " 47%|████▋     | 196083/414113 [00:45<00:50, 4301.73it/s]\u001b[A\n",
      " 47%|████▋     | 196525/414113 [00:45<00:50, 4335.14it/s]\u001b[A\n",
      " 48%|████▊     | 196977/414113 [00:45<00:49, 4388.48it/s]\u001b[A\n",
      " 48%|████▊     | 197417/414113 [00:45<00:49, 4386.23it/s]\u001b[A\n",
      " 48%|████▊     | 197866/414113 [00:45<00:48, 4414.84it/s]\u001b[A\n",
      " 48%|████▊     | 198312/414113 [00:46<00:48, 4426.49it/s]\u001b[A\n",
      " 48%|████▊     | 198755/414113 [00:46<00:48, 4414.78it/s]\u001b[A\n",
      " 48%|████▊     | 199197/414113 [00:46<00:48, 4410.89it/s]\u001b[A\n",
      " 48%|████▊     | 199639/414113 [00:46<00:48, 4401.69it/s]\u001b[A\n",
      " 48%|████▊     | 200080/414113 [00:46<00:48, 4375.46it/s]\u001b[A\n",
      " 48%|████▊     | 200526/414113 [00:46<00:48, 4399.80it/s]\u001b[A\n",
      " 49%|████▊     | 200973/414113 [00:46<00:48, 4419.85it/s]\u001b[A\n",
      " 49%|████▊     | 201430/414113 [00:46<00:47, 4462.11it/s]\u001b[A\n",
      " 49%|████▊     | 201877/414113 [00:46<00:47, 4447.41it/s]\u001b[A\n",
      " 49%|████▉     | 202322/414113 [00:46<00:47, 4434.11it/s]\u001b[A\n",
      " 49%|████▉     | 202766/414113 [00:47<00:47, 4432.97it/s]\u001b[A\n",
      " 49%|████▉     | 203215/414113 [00:47<00:47, 4447.82it/s]\u001b[A\n",
      " 49%|████▉     | 203660/414113 [00:47<00:47, 4448.06it/s]\u001b[A\n",
      " 49%|████▉     | 204105/414113 [00:47<00:48, 4313.26it/s]\u001b[A\n",
      " 49%|████▉     | 204553/414113 [00:47<00:48, 4361.53it/s]\u001b[A\n",
      " 50%|████▉     | 205001/414113 [00:47<00:47, 4395.76it/s]\u001b[A\n",
      " 50%|████▉     | 205449/414113 [00:47<00:47, 4418.30it/s]\u001b[A\n",
      " 50%|████▉     | 205892/414113 [00:47<00:47, 4398.80it/s]\u001b[A\n",
      " 50%|████▉     | 206333/414113 [00:47<00:47, 4382.73it/s]\u001b[A\n",
      " 50%|████▉     | 206772/414113 [00:47<00:47, 4356.38it/s]\u001b[A\n",
      " 50%|█████     | 207208/414113 [00:48<00:47, 4356.99it/s]\u001b[A\n",
      " 50%|█████     | 207647/414113 [00:48<00:47, 4366.80it/s]\u001b[A\n",
      " 50%|█████     | 208102/414113 [00:48<00:46, 4418.78it/s]\u001b[A\n",
      " 50%|█████     | 208545/414113 [00:48<00:46, 4411.38it/s]\u001b[A\n",
      " 50%|█████     | 208987/414113 [00:48<00:46, 4402.75it/s]\u001b[A\n",
      " 51%|█████     | 209432/414113 [00:48<00:46, 4413.33it/s]\u001b[A\n",
      " 51%|█████     | 209883/414113 [00:48<00:45, 4441.14it/s]\u001b[A\n",
      " 51%|█████     | 210328/414113 [00:48<00:46, 4423.69it/s]\u001b[A\n",
      " 51%|█████     | 210774/414113 [00:48<00:45, 4432.44it/s]\u001b[A\n",
      " 51%|█████     | 211219/414113 [00:48<00:45, 4435.10it/s]\u001b[A\n",
      " 51%|█████     | 211674/414113 [00:49<00:45, 4467.88it/s]\u001b[A\n",
      " 51%|█████     | 212128/414113 [00:49<00:45, 4486.81it/s]\u001b[A\n",
      " 51%|█████▏    | 212577/414113 [00:49<00:45, 4475.81it/s]\u001b[A\n",
      " 51%|█████▏    | 213025/414113 [00:49<00:45, 4453.95it/s]\u001b[A\n",
      " 52%|█████▏    | 213472/414113 [00:49<00:45, 4455.88it/s]\u001b[A\n",
      " 52%|█████▏    | 213922/414113 [00:49<00:44, 4467.89it/s]\u001b[A\n",
      " 52%|█████▏    | 214369/414113 [00:49<00:45, 4351.09it/s]\u001b[A\n",
      " 52%|█████▏    | 214817/414113 [00:49<00:45, 4388.29it/s]\u001b[A\n",
      " 52%|█████▏    | 215264/414113 [00:49<00:45, 4411.65it/s]\u001b[A\n",
      " 52%|█████▏    | 215706/414113 [00:49<00:45, 4367.60it/s]\u001b[A\n",
      " 52%|█████▏    | 216155/414113 [00:50<00:44, 4401.42it/s]\u001b[A\n",
      " 52%|█████▏    | 216596/414113 [00:50<00:45, 4381.77it/s]\u001b[A\n",
      " 52%|█████▏    | 217045/414113 [00:50<00:44, 4412.67it/s]\u001b[A\n",
      " 53%|█████▎    | 217491/414113 [00:50<00:44, 4424.37it/s]\u001b[A\n",
      " 53%|█████▎    | 217940/414113 [00:50<00:44, 4441.13it/s]\u001b[A\n",
      " 53%|█████▎    | 218393/414113 [00:50<00:43, 4465.75it/s]\u001b[A\n",
      " 53%|█████▎    | 218840/414113 [00:50<00:43, 4438.24it/s]\u001b[A\n",
      " 53%|█████▎    | 219286/414113 [00:50<00:43, 4442.37it/s]\u001b[A\n",
      " 53%|█████▎    | 219731/414113 [00:50<00:44, 4399.09it/s]\u001b[A\n",
      " 53%|█████▎    | 220172/414113 [00:50<00:44, 4399.01it/s]\u001b[A\n",
      " 53%|█████▎    | 220613/414113 [00:51<00:44, 4386.19it/s]\u001b[A\n",
      " 53%|█████▎    | 221062/414113 [00:51<00:43, 4415.66it/s]\u001b[A\n",
      " 53%|█████▎    | 221504/414113 [00:51<00:43, 4414.04it/s]\u001b[A\n",
      " 54%|█████▎    | 221949/414113 [00:51<00:43, 4423.91it/s]\u001b[A\n",
      " 54%|█████▎    | 222409/414113 [00:51<00:42, 4473.96it/s]\u001b[A\n",
      " 54%|█████▍    | 222857/414113 [00:51<00:42, 4459.77it/s]\u001b[A\n",
      " 54%|█████▍    | 223304/414113 [00:51<00:42, 4461.77it/s]\u001b[A\n",
      " 54%|█████▍    | 223758/414113 [00:51<00:42, 4483.67it/s]\u001b[A\n",
      " 54%|█████▍    | 224207/414113 [00:51<00:42, 4469.48it/s]\u001b[A\n",
      " 54%|█████▍    | 224655/414113 [00:51<00:42, 4451.50it/s]\u001b[A\n",
      " 54%|█████▍    | 225109/414113 [00:52<00:42, 4476.55it/s]\u001b[A\n",
      " 54%|█████▍    | 225557/414113 [00:52<00:42, 4468.16it/s]\u001b[A\n",
      " 55%|█████▍    | 226004/414113 [00:52<00:42, 4418.76it/s]\u001b[A\n",
      " 55%|█████▍    | 226457/414113 [00:52<00:42, 4450.69it/s]\u001b[A\n",
      " 55%|█████▍    | 226903/414113 [00:52<00:42, 4426.77it/s]\u001b[A\n",
      " 55%|█████▍    | 227350/414113 [00:52<00:42, 4438.10it/s]\u001b[A\n",
      " 55%|█████▌    | 227810/414113 [00:52<00:41, 4485.31it/s]\u001b[A\n",
      " 55%|█████▌    | 228259/414113 [00:52<00:41, 4482.91it/s]\u001b[A\n",
      " 55%|█████▌    | 228720/414113 [00:52<00:41, 4520.19it/s]\u001b[A\n",
      " 55%|█████▌    | 229173/414113 [00:52<00:41, 4466.88it/s]\u001b[A\n",
      " 55%|█████▌    | 229620/414113 [00:53<00:41, 4465.10it/s]\u001b[A\n",
      " 56%|█████▌    | 230067/414113 [00:53<00:41, 4434.53it/s]\u001b[A\n",
      " 56%|█████▌    | 230511/414113 [00:53<00:41, 4435.07it/s]\u001b[A\n",
      " 56%|█████▌    | 230956/414113 [00:53<00:41, 4439.53it/s]\u001b[A\n",
      " 56%|█████▌    | 231401/414113 [00:53<00:41, 4401.04it/s]\u001b[A\n",
      " 56%|█████▌    | 231842/414113 [00:53<00:41, 4386.77it/s]\u001b[A\n",
      " 56%|█████▌    | 232286/414113 [00:53<00:41, 4400.10it/s]\u001b[A\n",
      " 56%|█████▌    | 232727/414113 [00:53<00:41, 4351.92it/s]\u001b[A\n",
      " 56%|█████▋    | 233163/414113 [00:53<00:42, 4288.62it/s]\u001b[A\n",
      " 56%|█████▋    | 233600/414113 [00:54<00:41, 4311.01it/s]\u001b[A\n",
      " 57%|█████▋    | 234044/414113 [00:54<00:41, 4347.47it/s]\u001b[A\n",
      " 57%|█████▋    | 234484/414113 [00:54<00:41, 4360.13it/s]\u001b[A\n",
      " 57%|█████▋    | 234921/414113 [00:54<00:41, 4337.56it/s]\u001b[A\n",
      " 57%|█████▋    | 235355/414113 [00:54<00:41, 4279.13it/s]\u001b[A\n",
      " 57%|█████▋    | 235802/414113 [00:54<00:41, 4332.11it/s]\u001b[A\n",
      " 57%|█████▋    | 236236/414113 [00:54<00:41, 4308.45it/s]\u001b[A\n",
      " 57%|█████▋    | 236671/414113 [00:54<00:41, 4319.93it/s]\u001b[A\n",
      " 57%|█████▋    | 237104/414113 [00:54<00:40, 4317.89it/s]\u001b[A\n",
      " 57%|█████▋    | 237548/414113 [00:54<00:40, 4353.04it/s]\u001b[A\n",
      " 57%|█████▋    | 237984/414113 [00:55<00:40, 4311.36it/s]\u001b[A\n",
      " 58%|█████▊    | 238422/414113 [00:55<00:40, 4331.41it/s]\u001b[A\n",
      " 58%|█████▊    | 238856/414113 [00:55<00:40, 4304.15it/s]\u001b[A\n",
      " 58%|█████▊    | 239287/414113 [00:55<00:42, 4136.33it/s]\u001b[A\n",
      " 58%|█████▊    | 239709/414113 [00:55<00:41, 4158.57it/s]\u001b[A\n",
      " 58%|█████▊    | 240139/414113 [00:55<00:41, 4198.92it/s]\u001b[A\n",
      " 58%|█████▊    | 240577/414113 [00:55<00:40, 4249.40it/s]\u001b[A\n",
      " 58%|█████▊    | 241013/414113 [00:55<00:40, 4281.48it/s]\u001b[A\n",
      " 58%|█████▊    | 241448/414113 [00:55<00:40, 4299.54it/s]\u001b[A\n",
      " 58%|█████▊    | 241890/414113 [00:55<00:39, 4333.53it/s]\u001b[A\n",
      " 59%|█████▊    | 242324/414113 [00:56<00:39, 4333.77it/s]\u001b[A\n",
      " 59%|█████▊    | 242766/414113 [00:56<00:39, 4358.36it/s]\u001b[A\n",
      " 59%|█████▊    | 243203/414113 [00:56<00:39, 4310.65it/s]\u001b[A\n",
      " 59%|█████▉    | 243645/414113 [00:56<00:39, 4341.62it/s]\u001b[A\n",
      " 59%|█████▉    | 244083/414113 [00:56<00:39, 4351.22it/s]\u001b[A\n",
      " 59%|█████▉    | 244519/414113 [00:56<00:39, 4332.73it/s]\u001b[A\n",
      " 59%|█████▉    | 244959/414113 [00:56<00:38, 4352.22it/s]\u001b[A\n",
      " 59%|█████▉    | 245398/414113 [00:56<00:38, 4363.36it/s]\u001b[A\n",
      " 59%|█████▉    | 245835/414113 [00:56<00:38, 4329.86it/s]\u001b[A\n",
      " 59%|█████▉    | 246273/414113 [00:56<00:38, 4342.28it/s]\u001b[A\n",
      " 60%|█████▉    | 246713/414113 [00:57<00:38, 4358.64it/s]\u001b[A\n",
      " 60%|█████▉    | 247154/414113 [00:57<00:38, 4371.76it/s]\u001b[A\n",
      " 60%|█████▉    | 247592/414113 [00:57<00:38, 4346.47it/s]\u001b[A\n",
      " 60%|█████▉    | 248034/414113 [00:57<00:38, 4366.73it/s]\u001b[A\n",
      " 60%|██████    | 248471/414113 [00:57<00:37, 4364.99it/s]\u001b[A\n",
      " 60%|██████    | 248908/414113 [00:57<00:37, 4356.08it/s]\u001b[A\n",
      " 60%|██████    | 249354/414113 [00:57<00:37, 4386.53it/s]\u001b[A\n",
      " 60%|██████    | 249793/414113 [00:57<00:37, 4360.70it/s]\u001b[A\n",
      " 60%|██████    | 250235/414113 [00:57<00:37, 4376.17it/s]\u001b[A\n",
      " 61%|██████    | 250673/414113 [00:57<00:37, 4344.94it/s]\u001b[A\n",
      " 61%|██████    | 251124/414113 [00:58<00:37, 4391.73it/s]\u001b[A\n",
      " 61%|██████    | 251569/414113 [00:58<00:36, 4406.97it/s]\u001b[A\n",
      " 61%|██████    | 252010/414113 [00:58<00:36, 4403.37it/s]\u001b[A\n",
      " 61%|██████    | 252463/414113 [00:58<00:36, 4439.39it/s]\u001b[A\n",
      " 61%|██████    | 252908/414113 [00:58<00:36, 4418.98it/s]\u001b[A\n",
      " 61%|██████    | 253351/414113 [00:58<00:36, 4410.49it/s]\u001b[A\n",
      " 61%|██████▏   | 253796/414113 [00:58<00:36, 4420.54it/s]\u001b[A\n",
      " 61%|██████▏   | 254239/414113 [00:58<00:36, 4381.21it/s]\u001b[A\n",
      " 61%|██████▏   | 254678/414113 [00:58<00:36, 4379.73it/s]\u001b[A\n",
      " 62%|██████▏   | 255117/414113 [00:58<00:36, 4379.48it/s]\u001b[A\n",
      " 62%|██████▏   | 255566/414113 [00:59<00:35, 4410.27it/s]\u001b[A\n",
      " 62%|██████▏   | 256015/414113 [00:59<00:35, 4432.96it/s]\u001b[A\n",
      " 62%|██████▏   | 256468/414113 [00:59<00:35, 4460.87it/s]\u001b[A\n",
      " 62%|██████▏   | 256915/414113 [00:59<00:35, 4428.33it/s]\u001b[A\n",
      " 62%|██████▏   | 257365/414113 [00:59<00:35, 4447.57it/s]\u001b[A\n",
      " 62%|██████▏   | 257813/414113 [00:59<00:35, 4455.22it/s]\u001b[A\n",
      " 62%|██████▏   | 258259/414113 [00:59<00:35, 4424.85it/s]\u001b[A\n",
      " 62%|██████▏   | 258703/414113 [00:59<00:35, 4428.91it/s]\u001b[A\n",
      " 63%|██████▎   | 259146/414113 [00:59<00:35, 4387.20it/s]\u001b[A\n",
      " 63%|██████▎   | 259599/414113 [00:59<00:34, 4426.30it/s]\u001b[A\n",
      " 63%|██████▎   | 260042/414113 [01:00<00:35, 4399.92it/s]\u001b[A\n",
      " 63%|██████▎   | 260483/414113 [01:00<00:35, 4385.44it/s]\u001b[A\n",
      " 63%|██████▎   | 260930/414113 [01:00<00:34, 4410.27it/s]\u001b[A\n",
      " 63%|██████▎   | 261375/414113 [01:00<00:34, 4421.55it/s]\u001b[A\n",
      " 63%|██████▎   | 261818/414113 [01:00<00:34, 4405.48it/s]\u001b[A\n",
      " 63%|██████▎   | 262261/414113 [01:00<00:34, 4412.01it/s]\u001b[A\n",
      " 63%|██████▎   | 262705/414113 [01:00<00:34, 4418.03it/s]\u001b[A\n",
      " 64%|██████▎   | 263154/414113 [01:00<00:34, 4438.33it/s]\u001b[A\n",
      " 64%|██████▎   | 263598/414113 [01:00<00:34, 4404.66it/s]\u001b[A\n",
      " 64%|██████▍   | 264039/414113 [01:00<00:34, 4396.48it/s]\u001b[A\n",
      " 64%|██████▍   | 264479/414113 [01:01<00:34, 4381.97it/s]\u001b[A\n",
      " 64%|██████▍   | 264918/414113 [01:01<00:34, 4360.24it/s]\u001b[A\n",
      " 64%|██████▍   | 265355/414113 [01:01<00:34, 4346.89it/s]\u001b[A\n",
      " 64%|██████▍   | 265790/414113 [01:01<00:34, 4261.87it/s]\u001b[A\n",
      " 64%|██████▍   | 266217/414113 [01:01<00:34, 4255.75it/s]\u001b[A\n",
      " 64%|██████▍   | 266665/414113 [01:01<00:34, 4319.97it/s]\u001b[A\n",
      " 65%|██████▍   | 267107/414113 [01:01<00:33, 4348.22it/s]\u001b[A\n",
      " 65%|██████▍   | 267551/414113 [01:01<00:33, 4375.02it/s]\u001b[A\n",
      " 65%|██████▍   | 267989/414113 [01:01<00:33, 4366.58it/s]\u001b[A\n",
      " 65%|██████▍   | 268426/414113 [01:01<00:33, 4363.51it/s]\u001b[A\n",
      " 65%|██████▍   | 268863/414113 [01:02<00:33, 4352.55it/s]\u001b[A\n",
      " 65%|██████▌   | 269299/414113 [01:02<00:33, 4354.31it/s]\u001b[A\n",
      " 65%|██████▌   | 269737/414113 [01:02<00:33, 4361.08it/s]\u001b[A\n",
      " 65%|██████▌   | 270174/414113 [01:02<00:33, 4360.26it/s]\u001b[A\n",
      " 65%|██████▌   | 270617/414113 [01:02<00:32, 4379.93it/s]\u001b[A\n",
      " 65%|██████▌   | 271056/414113 [01:02<00:32, 4361.33it/s]\u001b[A\n",
      " 66%|██████▌   | 271502/414113 [01:02<00:32, 4388.37it/s]\u001b[A\n",
      " 66%|██████▌   | 271941/414113 [01:02<00:32, 4376.74it/s]\u001b[A\n",
      " 66%|██████▌   | 272379/414113 [01:02<00:32, 4349.24it/s]\u001b[A\n",
      " 66%|██████▌   | 272815/414113 [01:02<00:32, 4346.95it/s]\u001b[A\n",
      " 66%|██████▌   | 273254/414113 [01:03<00:32, 4357.57it/s]\u001b[A\n",
      " 66%|██████▌   | 273690/414113 [01:03<00:32, 4349.25it/s]\u001b[A\n",
      " 66%|██████▌   | 274125/414113 [01:03<00:32, 4334.79it/s]\u001b[A\n",
      " 66%|██████▋   | 274568/414113 [01:03<00:31, 4362.45it/s]\u001b[A\n",
      " 66%|██████▋   | 275005/414113 [01:03<00:32, 4328.00it/s]\u001b[A\n",
      " 67%|██████▋   | 275447/414113 [01:03<00:31, 4353.54it/s]\u001b[A\n",
      " 67%|██████▋   | 275890/414113 [01:03<00:31, 4374.25it/s]\u001b[A\n",
      " 67%|██████▋   | 276333/414113 [01:03<00:31, 4389.25it/s]\u001b[A\n",
      " 67%|██████▋   | 276773/414113 [01:03<00:31, 4376.69it/s]\u001b[A\n",
      " 67%|██████▋   | 277211/414113 [01:04<00:32, 4206.11it/s]\u001b[A\n",
      " 67%|██████▋   | 277658/414113 [01:04<00:31, 4281.75it/s]\u001b[A\n",
      " 67%|██████▋   | 278096/414113 [01:04<00:31, 4308.31it/s]\u001b[A\n",
      " 67%|██████▋   | 278535/414113 [01:04<00:31, 4330.81it/s]\u001b[A\n",
      " 67%|██████▋   | 278976/414113 [01:04<00:31, 4351.79it/s]\u001b[A\n",
      " 67%|██████▋   | 279412/414113 [01:04<00:31, 4313.64it/s]\u001b[A\n",
      " 68%|██████▊   | 279849/414113 [01:04<00:31, 4329.99it/s]\u001b[A\n",
      " 68%|██████▊   | 280291/414113 [01:04<00:30, 4354.58it/s]\u001b[A\n",
      " 68%|██████▊   | 280727/414113 [01:04<00:30, 4333.02it/s]\u001b[A\n",
      " 68%|██████▊   | 281171/414113 [01:04<00:30, 4362.57it/s]\u001b[A\n",
      " 68%|██████▊   | 281609/414113 [01:05<00:30, 4365.89it/s]\u001b[A\n",
      " 68%|██████▊   | 282053/414113 [01:05<00:30, 4387.86it/s]\u001b[A\n",
      " 68%|██████▊   | 282492/414113 [01:05<00:30, 4352.33it/s]\u001b[A\n",
      " 68%|██████▊   | 282929/414113 [01:05<00:30, 4357.43it/s]\u001b[A\n",
      " 68%|██████▊   | 283371/414113 [01:05<00:29, 4374.29it/s]\u001b[A\n",
      " 69%|██████▊   | 283827/414113 [01:05<00:29, 4426.75it/s]\u001b[A\n",
      " 69%|██████▊   | 284270/414113 [01:05<00:29, 4399.24it/s]\u001b[A\n",
      " 69%|██████▉   | 284721/414113 [01:05<00:29, 4428.58it/s]\u001b[A\n",
      " 69%|██████▉   | 285165/414113 [01:05<00:29, 4402.77it/s]\u001b[A\n",
      " 69%|██████▉   | 285612/414113 [01:05<00:29, 4422.43it/s]\u001b[A\n",
      " 69%|██████▉   | 286055/414113 [01:06<00:29, 4385.86it/s]\u001b[A\n",
      " 69%|██████▉   | 286495/414113 [01:06<00:29, 4388.07it/s]\u001b[A\n",
      " 69%|██████▉   | 286934/414113 [01:06<00:28, 4387.04it/s]\u001b[A\n",
      " 69%|██████▉   | 287378/414113 [01:06<00:28, 4402.44it/s]\u001b[A\n",
      " 70%|██████▉   | 287821/414113 [01:06<00:28, 4409.45it/s]\u001b[A\n",
      " 70%|██████▉   | 288262/414113 [01:06<00:28, 4409.16it/s]\u001b[A\n",
      " 70%|██████▉   | 288707/414113 [01:06<00:28, 4421.14it/s]\u001b[A\n",
      " 70%|██████▉   | 289150/414113 [01:06<00:28, 4421.86it/s]\u001b[A\n",
      " 70%|██████▉   | 289593/414113 [01:06<00:28, 4402.34it/s]\u001b[A\n",
      " 70%|███████   | 290034/414113 [01:06<00:28, 4388.70it/s]\u001b[A\n",
      " 70%|███████   | 290486/414113 [01:07<00:27, 4425.09it/s]\u001b[A\n",
      " 70%|███████   | 290929/414113 [01:07<00:27, 4401.13it/s]\u001b[A\n",
      " 70%|███████   | 291370/414113 [01:07<00:27, 4403.70it/s]\u001b[A\n",
      " 70%|███████   | 291811/414113 [01:07<00:27, 4400.18it/s]\u001b[A\n",
      " 71%|███████   | 292252/414113 [01:07<00:28, 4212.66it/s]\u001b[A\n",
      " 71%|███████   | 292697/414113 [01:07<00:28, 4278.79it/s]\u001b[A\n",
      " 71%|███████   | 293149/414113 [01:07<00:27, 4348.15it/s]\u001b[A\n",
      " 71%|███████   | 293589/414113 [01:07<00:27, 4360.48it/s]\u001b[A\n",
      " 71%|███████   | 294026/414113 [01:07<00:27, 4348.58it/s]\u001b[A\n",
      " 71%|███████   | 294469/414113 [01:07<00:27, 4370.92it/s]\u001b[A\n",
      " 71%|███████   | 294907/414113 [01:08<00:27, 4336.21it/s]\u001b[A\n",
      " 71%|███████▏  | 295353/414113 [01:08<00:27, 4369.44it/s]\u001b[A\n",
      " 71%|███████▏  | 295803/414113 [01:08<00:26, 4406.38it/s]\u001b[A\n",
      " 72%|███████▏  | 296249/414113 [01:08<00:26, 4422.23it/s]\u001b[A\n",
      " 72%|███████▏  | 296700/414113 [01:08<00:26, 4445.78it/s]\u001b[A\n",
      " 72%|███████▏  | 297145/414113 [01:08<00:26, 4433.33it/s]\u001b[A\n",
      " 72%|███████▏  | 297589/414113 [01:08<00:26, 4334.93it/s]\u001b[A\n",
      " 72%|███████▏  | 298024/414113 [01:08<00:26, 4322.92it/s]\u001b[A\n",
      " 72%|███████▏  | 298463/414113 [01:08<00:26, 4342.81it/s]\u001b[A\n",
      " 72%|███████▏  | 298898/414113 [01:08<00:26, 4335.13it/s]\u001b[A\n",
      " 72%|███████▏  | 299332/414113 [01:09<00:26, 4333.37it/s]\u001b[A\n",
      " 72%|███████▏  | 299782/414113 [01:09<00:26, 4381.34it/s]\u001b[A\n",
      " 72%|███████▏  | 300223/414113 [01:09<00:25, 4388.93it/s]\u001b[A\n",
      " 73%|███████▎  | 300663/414113 [01:09<00:25, 4383.87it/s]\u001b[A\n",
      " 73%|███████▎  | 301102/414113 [01:09<00:25, 4383.03it/s]\u001b[A\n",
      " 73%|███████▎  | 301541/414113 [01:09<00:25, 4380.37it/s]\u001b[A\n",
      " 73%|███████▎  | 301980/414113 [01:09<00:25, 4379.41it/s]\u001b[A\n",
      " 73%|███████▎  | 302430/414113 [01:09<00:25, 4413.36it/s]\u001b[A\n",
      " 73%|███████▎  | 302872/414113 [01:09<00:25, 4406.07it/s]\u001b[A\n",
      " 73%|███████▎  | 303313/414113 [01:09<00:25, 4356.52it/s]\u001b[A\n",
      " 73%|███████▎  | 303754/414113 [01:10<00:25, 4371.60it/s]\u001b[A\n",
      " 73%|███████▎  | 304192/414113 [01:10<00:25, 4342.02it/s]\u001b[A\n",
      " 74%|███████▎  | 304639/414113 [01:10<00:25, 4378.36it/s]\u001b[A\n",
      " 74%|███████▎  | 305078/414113 [01:10<00:24, 4379.16it/s]\u001b[A\n",
      " 74%|███████▍  | 305518/414113 [01:10<00:24, 4383.72it/s]\u001b[A\n",
      " 74%|███████▍  | 305957/414113 [01:10<00:24, 4358.59it/s]\u001b[A\n",
      " 74%|███████▍  | 306397/414113 [01:10<00:24, 4369.03it/s]\u001b[A\n",
      " 74%|███████▍  | 306838/414113 [01:10<00:24, 4377.10it/s]\u001b[A\n",
      " 74%|███████▍  | 307278/414113 [01:10<00:24, 4383.39it/s]\u001b[A\n",
      " 74%|███████▍  | 307717/414113 [01:10<00:24, 4377.08it/s]\u001b[A\n",
      " 74%|███████▍  | 308162/414113 [01:11<00:24, 4398.05it/s]\u001b[A\n",
      " 75%|███████▍  | 308602/414113 [01:11<00:24, 4389.41it/s]\u001b[A\n",
      " 75%|███████▍  | 309045/414113 [01:11<00:23, 4400.84it/s]\u001b[A\n",
      " 75%|███████▍  | 309487/414113 [01:11<00:23, 4405.97it/s]\u001b[A\n",
      " 75%|███████▍  | 309931/414113 [01:11<00:23, 4416.03it/s]\u001b[A\n",
      " 75%|███████▍  | 310373/414113 [01:11<00:23, 4357.50it/s]\u001b[A\n",
      " 75%|███████▌  | 310810/414113 [01:11<00:23, 4359.75it/s]\u001b[A\n",
      " 75%|███████▌  | 311248/414113 [01:11<00:23, 4362.61it/s]\u001b[A\n",
      " 75%|███████▌  | 311692/414113 [01:11<00:23, 4381.21it/s]\u001b[A\n",
      " 75%|███████▌  | 312131/414113 [01:11<00:23, 4382.50it/s]\u001b[A\n",
      " 75%|███████▌  | 312578/414113 [01:12<00:23, 4407.53it/s]\u001b[A\n",
      " 76%|███████▌  | 313030/414113 [01:12<00:22, 4438.05it/s]\u001b[A\n",
      " 76%|███████▌  | 313474/414113 [01:12<00:22, 4427.10it/s]\u001b[A\n",
      " 76%|███████▌  | 313917/414113 [01:12<00:22, 4403.88it/s]\u001b[A\n",
      " 76%|███████▌  | 314360/414113 [01:12<00:22, 4410.64it/s]\u001b[A\n",
      " 76%|███████▌  | 314802/414113 [01:12<00:22, 4413.42it/s]\u001b[A\n",
      " 76%|███████▌  | 315244/414113 [01:12<00:22, 4412.50it/s]\u001b[A\n",
      " 76%|███████▌  | 315686/414113 [01:12<00:22, 4414.43it/s]\u001b[A\n",
      " 76%|███████▋  | 316142/414113 [01:12<00:21, 4455.92it/s]\u001b[A\n",
      " 76%|███████▋  | 316588/414113 [01:12<00:22, 4426.98it/s]\u001b[A\n",
      " 77%|███████▋  | 317032/414113 [01:13<00:21, 4430.55it/s]\u001b[A\n",
      " 77%|███████▋  | 317487/414113 [01:13<00:21, 4463.27it/s]\u001b[A\n",
      " 77%|███████▋  | 317934/414113 [01:13<00:21, 4424.93it/s]\u001b[A\n",
      " 77%|███████▋  | 318383/414113 [01:13<00:21, 4443.37it/s]\u001b[A\n",
      " 77%|███████▋  | 318828/414113 [01:13<00:21, 4431.14it/s]\u001b[A\n",
      " 77%|███████▋  | 319274/414113 [01:13<00:21, 4438.61it/s]\u001b[A\n",
      " 77%|███████▋  | 319725/414113 [01:13<00:21, 4459.03it/s]\u001b[A\n",
      " 77%|███████▋  | 320179/414113 [01:13<00:20, 4480.99it/s]\u001b[A\n",
      " 77%|███████▋  | 320633/414113 [01:13<00:20, 4498.22it/s]\u001b[A\n",
      " 78%|███████▊  | 321083/414113 [01:14<00:20, 4474.86it/s]\u001b[A\n",
      " 78%|███████▊  | 321535/414113 [01:14<00:20, 4488.18it/s]\u001b[A\n",
      " 78%|███████▊  | 321984/414113 [01:14<00:21, 4309.29it/s]\u001b[A\n",
      " 78%|███████▊  | 322417/414113 [01:14<00:21, 4307.09it/s]\u001b[A\n",
      " 78%|███████▊  | 322855/414113 [01:14<00:21, 4325.95it/s]\u001b[A\n",
      " 78%|███████▊  | 323309/414113 [01:14<00:20, 4385.77it/s]\u001b[A\n",
      " 78%|███████▊  | 323749/414113 [01:14<00:20, 4385.56it/s]\u001b[A\n",
      " 78%|███████▊  | 324191/414113 [01:14<00:20, 4393.80it/s]\u001b[A\n",
      " 78%|███████▊  | 324636/414113 [01:14<00:20, 4410.45it/s]\u001b[A\n",
      " 78%|███████▊  | 325078/414113 [01:14<00:20, 4408.24it/s]\u001b[A\n",
      " 79%|███████▊  | 325525/414113 [01:15<00:20, 4423.55it/s]\u001b[A\n",
      " 79%|███████▊  | 325968/414113 [01:15<00:19, 4422.00it/s]\u001b[A\n",
      " 79%|███████▉  | 326424/414113 [01:15<00:19, 4460.30it/s]\u001b[A\n",
      " 79%|███████▉  | 326871/414113 [01:15<00:19, 4437.93it/s]\u001b[A\n",
      " 79%|███████▉  | 327315/414113 [01:15<00:19, 4421.38it/s]\u001b[A\n",
      " 79%|███████▉  | 327758/414113 [01:15<00:39, 2182.53it/s]\u001b[A\n",
      " 79%|███████▉  | 328192/414113 [01:15<00:33, 2564.37it/s]\u001b[A\n",
      " 79%|███████▉  | 328629/414113 [01:16<00:29, 2925.99it/s]\u001b[A\n",
      " 79%|███████▉  | 329063/414113 [01:16<00:26, 3241.44it/s]\u001b[A\n",
      " 80%|███████▉  | 329500/414113 [01:16<00:24, 3512.15it/s]\u001b[A\n",
      " 80%|███████▉  | 329922/414113 [01:16<00:22, 3696.08it/s]\u001b[A\n",
      " 80%|███████▉  | 330348/414113 [01:16<00:21, 3846.92it/s]\u001b[A\n",
      " 80%|███████▉  | 330770/414113 [01:16<00:21, 3950.67it/s]\u001b[A\n",
      " 80%|███████▉  | 331190/414113 [01:16<00:20, 4019.04it/s]\u001b[A\n",
      " 80%|████████  | 331624/414113 [01:16<00:20, 4109.65it/s]\u001b[A\n",
      " 80%|████████  | 332062/414113 [01:16<00:19, 4184.48it/s]\u001b[A\n",
      " 80%|████████  | 332499/414113 [01:16<00:19, 4236.08it/s]\u001b[A\n",
      " 80%|████████  | 332938/414113 [01:17<00:18, 4278.65it/s]\u001b[A\n",
      " 81%|████████  | 333379/414113 [01:17<00:18, 4313.75it/s]\u001b[A\n",
      " 81%|████████  | 333817/414113 [01:17<00:18, 4330.39it/s]\u001b[A\n",
      " 81%|████████  | 334261/414113 [01:17<00:18, 4360.55it/s]\u001b[A\n",
      " 81%|████████  | 334701/414113 [01:17<00:18, 4371.16it/s]\u001b[A\n",
      " 81%|████████  | 335140/414113 [01:17<00:18, 4364.62it/s]\u001b[A\n",
      " 81%|████████  | 335578/414113 [01:17<00:17, 4364.60it/s]\u001b[A\n",
      " 81%|████████  | 336016/414113 [01:17<00:18, 4333.52it/s]\u001b[A\n",
      " 81%|████████  | 336450/414113 [01:17<00:17, 4330.44it/s]\u001b[A\n",
      " 81%|████████▏ | 336884/414113 [01:17<00:17, 4320.05it/s]\u001b[A\n",
      " 81%|████████▏ | 337317/414113 [01:18<00:17, 4318.74it/s]\u001b[A\n",
      " 82%|████████▏ | 337750/414113 [01:18<00:17, 4301.94it/s]\u001b[A\n",
      " 82%|████████▏ | 338181/414113 [01:18<00:17, 4287.32it/s]\u001b[A\n",
      " 82%|████████▏ | 338620/414113 [01:18<00:17, 4315.55it/s]\u001b[A\n",
      " 82%|████████▏ | 339052/414113 [01:18<00:17, 4302.06it/s]\u001b[A\n",
      " 82%|████████▏ | 339483/414113 [01:18<00:18, 4074.45it/s]\u001b[A\n",
      " 82%|████████▏ | 339912/414113 [01:18<00:17, 4136.27it/s]\u001b[A\n",
      " 82%|████████▏ | 340346/414113 [01:18<00:17, 4193.16it/s]\u001b[A\n",
      " 82%|████████▏ | 340792/414113 [01:18<00:17, 4266.60it/s]\u001b[A\n",
      " 82%|████████▏ | 341221/414113 [01:18<00:17, 4259.12it/s]\u001b[A\n",
      " 83%|████████▎ | 341652/414113 [01:19<00:16, 4274.24it/s]\u001b[A\n",
      " 83%|████████▎ | 342086/414113 [01:19<00:16, 4293.31it/s]\u001b[A\n",
      " 83%|████████▎ | 342522/414113 [01:19<00:16, 4311.47it/s]\u001b[A\n",
      " 83%|████████▎ | 342955/414113 [01:19<00:16, 4316.64it/s]\u001b[A\n",
      " 83%|████████▎ | 343388/414113 [01:19<00:16, 4319.22it/s]\u001b[A\n",
      " 83%|████████▎ | 343826/414113 [01:19<00:16, 4335.50it/s]\u001b[A\n",
      " 83%|████████▎ | 344260/414113 [01:19<00:16, 4308.85it/s]\u001b[A\n",
      " 83%|████████▎ | 344692/414113 [01:19<00:16, 4279.27it/s]\u001b[A\n",
      " 83%|████████▎ | 345123/414113 [01:19<00:16, 4285.85it/s]\u001b[A\n",
      " 83%|████████▎ | 345563/414113 [01:20<00:15, 4318.93it/s]\u001b[A\n",
      " 84%|████████▎ | 346002/414113 [01:20<00:15, 4338.37it/s]\u001b[A\n",
      " 84%|████████▎ | 346436/414113 [01:20<00:15, 4320.15it/s]\u001b[A\n",
      " 84%|████████▍ | 346875/414113 [01:20<00:15, 4338.53it/s]\u001b[A\n",
      " 84%|████████▍ | 347309/414113 [01:20<00:15, 4324.19it/s]\u001b[A\n",
      " 84%|████████▍ | 347742/414113 [01:20<00:15, 4322.03it/s]\u001b[A\n",
      " 84%|████████▍ | 348175/414113 [01:20<00:15, 4323.49it/s]\u001b[A\n",
      " 84%|████████▍ | 348608/414113 [01:20<00:15, 4275.43it/s]\u001b[A\n",
      " 84%|████████▍ | 349048/414113 [01:20<00:15, 4310.62it/s]\u001b[A\n",
      " 84%|████████▍ | 349483/414113 [01:20<00:14, 4320.12it/s]\u001b[A\n",
      " 84%|████████▍ | 349924/414113 [01:21<00:14, 4344.94it/s]\u001b[A\n",
      " 85%|████████▍ | 350359/414113 [01:21<00:14, 4343.80it/s]\u001b[A\n",
      " 85%|████████▍ | 350811/414113 [01:21<00:14, 4394.54it/s]\u001b[A\n",
      " 85%|████████▍ | 351260/414113 [01:21<00:14, 4420.17it/s]\u001b[A\n",
      " 85%|████████▍ | 351703/414113 [01:21<00:14, 4410.06it/s]\u001b[A\n",
      " 85%|████████▌ | 352145/414113 [01:21<00:14, 4407.97it/s]\u001b[A\n",
      " 85%|████████▌ | 352586/414113 [01:21<00:14, 4384.76it/s]\u001b[A\n",
      " 85%|████████▌ | 353025/414113 [01:21<00:14, 4308.52it/s]\u001b[A\n",
      " 85%|████████▌ | 353474/414113 [01:21<00:13, 4359.51it/s]\u001b[A\n",
      " 85%|████████▌ | 353912/414113 [01:21<00:13, 4364.67it/s]\u001b[A\n",
      " 86%|████████▌ | 354349/414113 [01:22<00:13, 4349.47it/s]\u001b[A\n",
      " 86%|████████▌ | 354792/414113 [01:22<00:13, 4370.44it/s]\u001b[A\n",
      " 86%|████████▌ | 355230/414113 [01:22<00:13, 4361.55it/s]\u001b[A\n",
      " 86%|████████▌ | 355676/414113 [01:22<00:13, 4389.77it/s]\u001b[A\n",
      " 86%|████████▌ | 356116/414113 [01:22<00:13, 4370.90it/s]\u001b[A\n",
      " 86%|████████▌ | 356554/414113 [01:22<00:13, 4369.65it/s]\u001b[A\n",
      " 86%|████████▌ | 356992/414113 [01:22<00:13, 4368.28it/s]\u001b[A\n",
      " 86%|████████▋ | 357429/414113 [01:22<00:13, 4316.18it/s]\u001b[A\n",
      " 86%|████████▋ | 357862/414113 [01:22<00:13, 4317.92it/s]\u001b[A\n",
      " 87%|████████▋ | 358298/414113 [01:22<00:12, 4327.76it/s]\u001b[A\n",
      " 87%|████████▋ | 358731/414113 [01:23<00:13, 4148.02it/s]\u001b[A\n",
      " 87%|████████▋ | 359178/414113 [01:23<00:12, 4239.45it/s]\u001b[A\n",
      " 87%|████████▋ | 359609/414113 [01:23<00:12, 4257.72it/s]\u001b[A\n",
      " 87%|████████▋ | 360052/414113 [01:23<00:12, 4305.33it/s]\u001b[A\n",
      " 87%|████████▋ | 360491/414113 [01:23<00:12, 4328.28it/s]\u001b[A\n",
      " 87%|████████▋ | 360925/414113 [01:23<00:12, 4331.31it/s]\u001b[A\n",
      " 87%|████████▋ | 361366/414113 [01:23<00:12, 4354.20it/s]\u001b[A\n",
      " 87%|████████▋ | 361809/414113 [01:23<00:11, 4376.12it/s]\u001b[A\n",
      " 87%|████████▋ | 362247/414113 [01:23<00:11, 4372.96it/s]\u001b[A\n",
      " 88%|████████▊ | 362685/414113 [01:23<00:11, 4358.37it/s]\u001b[A\n",
      " 88%|████████▊ | 363121/414113 [01:24<00:11, 4347.95it/s]\u001b[A\n",
      " 88%|████████▊ | 363560/414113 [01:24<00:11, 4358.83it/s]\u001b[A\n",
      " 88%|████████▊ | 363996/414113 [01:24<00:11, 4321.41it/s]\u001b[A\n",
      " 88%|████████▊ | 364443/414113 [01:24<00:11, 4364.45it/s]\u001b[A\n",
      " 88%|████████▊ | 364881/414113 [01:24<00:11, 4369.06it/s]\u001b[A\n",
      " 88%|████████▊ | 365319/414113 [01:24<00:11, 4372.30it/s]\u001b[A\n",
      " 88%|████████▊ | 365760/414113 [01:24<00:11, 4382.89it/s]\u001b[A\n",
      " 88%|████████▊ | 366199/414113 [01:24<00:10, 4361.23it/s]\u001b[A\n",
      " 89%|████████▊ | 366644/414113 [01:24<00:10, 4385.40it/s]\u001b[A\n",
      " 89%|████████▊ | 367083/414113 [01:24<00:10, 4363.94it/s]\u001b[A\n",
      " 89%|████████▊ | 367520/414113 [01:25<00:10, 4248.43it/s]\u001b[A\n",
      " 89%|████████▉ | 367957/414113 [01:25<00:10, 4283.62it/s]\u001b[A\n",
      " 89%|████████▉ | 368402/414113 [01:25<00:10, 4329.81it/s]\u001b[A\n",
      " 89%|████████▉ | 368843/414113 [01:25<00:10, 4352.84it/s]\u001b[A\n",
      " 89%|████████▉ | 369279/414113 [01:25<00:10, 4347.74it/s]\u001b[A\n",
      " 89%|████████▉ | 369715/414113 [01:25<00:10, 4339.90it/s]\u001b[A\n",
      " 89%|████████▉ | 370150/414113 [01:25<00:10, 4324.70it/s]\u001b[A\n",
      " 89%|████████▉ | 370583/414113 [01:25<00:10, 4303.03it/s]\u001b[A\n",
      " 90%|████████▉ | 371014/414113 [01:25<00:10, 4253.53it/s]\u001b[A\n",
      " 90%|████████▉ | 371440/414113 [01:25<00:10, 4246.44it/s]\u001b[A\n",
      " 90%|████████▉ | 371870/414113 [01:26<00:09, 4261.43it/s]\u001b[A\n",
      " 90%|████████▉ | 372310/414113 [01:26<00:09, 4300.11it/s]\u001b[A\n",
      " 90%|█████████ | 372741/414113 [01:26<00:09, 4293.09it/s]\u001b[A\n",
      " 90%|█████████ | 373180/414113 [01:26<00:09, 4320.94it/s]\u001b[A\n",
      " 90%|█████████ | 373613/414113 [01:26<00:09, 4317.07it/s]\u001b[A\n",
      " 90%|█████████ | 374051/414113 [01:26<00:09, 4333.87it/s]\u001b[A\n",
      " 90%|█████████ | 374498/414113 [01:26<00:09, 4371.69it/s]\u001b[A\n",
      " 91%|█████████ | 374939/414113 [01:26<00:08, 4380.58it/s]\u001b[A\n",
      " 91%|█████████ | 375378/414113 [01:26<00:08, 4376.26it/s]\u001b[A\n",
      " 91%|█████████ | 375816/414113 [01:26<00:08, 4372.44it/s]\u001b[A\n",
      " 91%|█████████ | 376254/414113 [01:27<00:08, 4361.07it/s]\u001b[A\n",
      " 91%|█████████ | 376691/414113 [01:27<00:08, 4346.75it/s]\u001b[A\n",
      " 91%|█████████ | 377127/414113 [01:27<00:08, 4349.83it/s]\u001b[A\n",
      " 91%|█████████ | 377563/414113 [01:27<00:08, 4333.34it/s]\u001b[A\n",
      " 91%|█████████▏| 377997/414113 [01:27<00:08, 4331.60it/s]\u001b[A\n",
      " 91%|█████████▏| 378436/414113 [01:27<00:08, 4346.79it/s]\u001b[A\n",
      " 91%|█████████▏| 378878/414113 [01:27<00:08, 4366.44it/s]\u001b[A\n",
      " 92%|█████████▏| 379315/414113 [01:27<00:08, 4346.36it/s]\u001b[A\n",
      " 92%|█████████▏| 379750/414113 [01:27<00:07, 4341.79it/s]\u001b[A\n",
      " 92%|█████████▏| 380185/414113 [01:27<00:07, 4316.19it/s]\u001b[A\n",
      " 92%|█████████▏| 380622/414113 [01:28<00:07, 4332.02it/s]\u001b[A\n",
      " 92%|█████████▏| 381061/414113 [01:28<00:07, 4346.58it/s]\u001b[A\n",
      " 92%|█████████▏| 381496/414113 [01:28<00:07, 4233.60it/s]\u001b[A\n",
      " 92%|█████████▏| 381936/414113 [01:28<00:07, 4280.96it/s]\u001b[A\n",
      " 92%|█████████▏| 382368/414113 [01:28<00:07, 4292.44it/s]\u001b[A\n",
      " 92%|█████████▏| 382812/414113 [01:28<00:07, 4333.29it/s]\u001b[A\n",
      " 93%|█████████▎| 383246/414113 [01:28<00:07, 4331.77it/s]\u001b[A\n",
      " 93%|█████████▎| 383695/414113 [01:28<00:06, 4377.39it/s]\u001b[A\n",
      " 93%|█████████▎| 384134/414113 [01:28<00:06, 4371.50it/s]\u001b[A\n",
      " 93%|█████████▎| 384572/414113 [01:28<00:06, 4360.57it/s]\u001b[A\n",
      " 93%|█████████▎| 385013/414113 [01:29<00:06, 4373.99it/s]\u001b[A\n",
      " 93%|█████████▎| 385451/414113 [01:29<00:06, 4357.17it/s]\u001b[A\n",
      " 93%|█████████▎| 385887/414113 [01:29<00:06, 4353.71it/s]\u001b[A\n",
      " 93%|█████████▎| 386325/414113 [01:29<00:06, 4361.54it/s]\u001b[A\n",
      " 93%|█████████▎| 386763/414113 [01:29<00:06, 4365.81it/s]\u001b[A\n",
      " 94%|█████████▎| 387200/414113 [01:29<00:06, 4291.77it/s]\u001b[A\n",
      " 94%|█████████▎| 387647/414113 [01:29<00:06, 4342.32it/s]\u001b[A\n",
      " 94%|█████████▎| 388082/414113 [01:29<00:06, 4325.34it/s]\u001b[A\n",
      " 94%|█████████▍| 388524/414113 [01:29<00:05, 4351.21it/s]\u001b[A\n",
      " 94%|█████████▍| 388972/414113 [01:30<00:05, 4385.98it/s]\u001b[A\n",
      " 94%|█████████▍| 389412/414113 [01:30<00:05, 4388.51it/s]\u001b[A\n",
      " 94%|█████████▍| 389858/414113 [01:30<00:05, 4408.20it/s]\u001b[A\n",
      " 94%|█████████▍| 390299/414113 [01:30<00:05, 4397.84it/s]\u001b[A\n",
      " 94%|█████████▍| 390739/414113 [01:30<00:05, 4385.79it/s]\u001b[A\n",
      " 94%|█████████▍| 391180/414113 [01:30<00:05, 4389.60it/s]\u001b[A\n",
      " 95%|█████████▍| 391634/414113 [01:30<00:05, 4433.21it/s]\u001b[A\n",
      " 95%|█████████▍| 392078/414113 [01:30<00:05, 4401.45it/s]\u001b[A\n",
      " 95%|█████████▍| 392520/414113 [01:30<00:04, 4404.42it/s]\u001b[A\n",
      " 95%|█████████▍| 392961/414113 [01:30<00:04, 4367.22it/s]\u001b[A\n",
      " 95%|█████████▍| 393398/414113 [01:31<00:04, 4314.16it/s]\u001b[A\n",
      " 95%|█████████▌| 393834/414113 [01:31<00:04, 4327.07it/s]\u001b[A\n",
      " 95%|█████████▌| 394267/414113 [01:31<00:04, 4310.96it/s]\u001b[A\n",
      " 95%|█████████▌| 394699/414113 [01:31<00:04, 4303.70it/s]\u001b[A\n",
      " 95%|█████████▌| 395130/414113 [01:31<00:04, 4304.30it/s]\u001b[A\n",
      " 96%|█████████▌| 395565/414113 [01:31<00:04, 4315.80it/s]\u001b[A\n",
      " 96%|█████████▌| 396002/414113 [01:31<00:04, 4331.20it/s]\u001b[A\n",
      " 96%|█████████▌| 396447/414113 [01:31<00:04, 4366.02it/s]\u001b[A\n",
      " 96%|█████████▌| 396895/414113 [01:31<00:03, 4398.05it/s]\u001b[A\n",
      " 96%|█████████▌| 397335/414113 [01:31<00:03, 4359.60it/s]\u001b[A\n",
      " 96%|█████████▌| 397778/414113 [01:32<00:03, 4378.23it/s]\u001b[A\n",
      " 96%|█████████▌| 398216/414113 [01:32<00:03, 4355.78it/s]\u001b[A\n",
      " 96%|█████████▋| 398659/414113 [01:32<00:03, 4376.83it/s]\u001b[A\n",
      " 96%|█████████▋| 399097/414113 [01:32<00:03, 4376.16it/s]\u001b[A\n",
      " 96%|█████████▋| 399537/414113 [01:32<00:03, 4382.29it/s]\u001b[A\n",
      " 97%|█████████▋| 399976/414113 [01:32<00:03, 4341.19it/s]\u001b[A\n",
      " 97%|█████████▋| 400415/414113 [01:32<00:03, 4355.15it/s]\u001b[A\n",
      " 97%|█████████▋| 400856/414113 [01:32<00:03, 4367.70it/s]\u001b[A\n",
      " 97%|█████████▋| 401294/414113 [01:32<00:02, 4370.73it/s]\u001b[A\n",
      " 97%|█████████▋| 401737/414113 [01:32<00:02, 4388.24it/s]\u001b[A\n",
      " 97%|█████████▋| 402176/414113 [01:33<00:02, 4388.57it/s]\u001b[A\n",
      " 97%|█████████▋| 402616/414113 [01:33<00:02, 4389.47it/s]\u001b[A\n",
      " 97%|█████████▋| 403060/414113 [01:33<00:02, 4403.00it/s]\u001b[A\n",
      " 97%|█████████▋| 403501/414113 [01:33<00:02, 4393.74it/s]\u001b[A\n",
      " 98%|█████████▊| 403942/414113 [01:33<00:02, 4397.75it/s]\u001b[A\n",
      " 98%|█████████▊| 404393/414113 [01:33<00:02, 4429.71it/s]\u001b[A\n",
      " 98%|█████████▊| 404837/414113 [01:33<00:02, 4420.63it/s]\u001b[A\n",
      " 98%|█████████▊| 405280/414113 [01:33<00:02, 4405.30it/s]\u001b[A\n",
      " 98%|█████████▊| 405735/414113 [01:33<00:01, 4445.12it/s]\u001b[A\n",
      " 98%|█████████▊| 406180/414113 [01:33<00:01, 4424.37it/s]\u001b[A\n",
      " 98%|█████████▊| 406623/414113 [01:34<00:01, 4425.91it/s]\u001b[A\n",
      " 98%|█████████▊| 407078/414113 [01:34<00:01, 4459.98it/s]\u001b[A\n",
      " 98%|█████████▊| 407531/414113 [01:34<00:01, 4480.03it/s]\u001b[A\n",
      " 99%|█████████▊| 407980/414113 [01:34<00:01, 4473.10it/s]\u001b[A\n",
      " 99%|█████████▊| 408428/414113 [01:34<00:01, 4410.86it/s]\u001b[A\n",
      " 99%|█████████▊| 408870/414113 [01:34<00:01, 4404.45it/s]\u001b[A\n",
      " 99%|█████████▉| 409311/414113 [01:34<00:01, 4399.84it/s]\u001b[A\n",
      " 99%|█████████▉| 409752/414113 [01:34<00:00, 4396.31it/s]\u001b[A\n",
      " 99%|█████████▉| 410192/414113 [01:34<00:00, 4385.85it/s]\u001b[A\n",
      " 99%|█████████▉| 410632/414113 [01:34<00:00, 4388.57it/s]\u001b[A\n",
      " 99%|█████████▉| 411071/414113 [01:35<00:00, 4372.37it/s]\u001b[A\n",
      " 99%|█████████▉| 411522/414113 [01:35<00:00, 4410.75it/s]\u001b[A\n",
      " 99%|█████████▉| 411964/414113 [01:35<00:00, 4407.31it/s]\u001b[A\n",
      "100%|█████████▉| 412405/414113 [01:35<00:00, 4388.40it/s]\u001b[A\n",
      "100%|█████████▉| 412849/414113 [01:35<00:00, 4401.59it/s]\u001b[A\n",
      "100%|█████████▉| 413292/414113 [01:35<00:00, 4408.89it/s]\u001b[A\n",
      "100%|█████████▉| 413741/414113 [01:35<00:00, 4431.34it/s]\u001b[A\n",
      "100%|██████████| 414113/414113 [01:35<00:00, 4325.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.90s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "\n",
    "\n",
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "batch_size = 64          # batch size\n",
    "vocab_threshold = 5        # minimum word count threshold\n",
    "vocab_from_file = True    # if True, load existing vocab file\n",
    "embed_size = 512           # dimensionality of image and word embeddings\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 6             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters())\n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "optimizer = torch.optim.Adam(params, lr=0.001, betas=(0.9,0.999), eps=1e-08)\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Train your Model\n",
    "\n",
    "Once you have executed the code cell in **Step 1**, the training procedure below should run without issue.  \n",
    "\n",
    "It is completely fine to leave the code cell below as-is without modifications to train your model.  However, if you would like to modify the code used to train the model below, you must ensure that your changes are easily parsed by your reviewer.  In other words, make sure to provide appropriate comments to describe how your code works!  \n",
    "\n",
    "You may find it useful to load saved weights to resume training.  In that case, note the names of the files containing the encoder and decoder weights that you'd like to load (`encoder_file` and `decoder_file`).  Then you can load the weights by using the lines below:\n",
    "\n",
    "```python\n",
    "# Load pre-trained weights before resuming training.\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n",
    "```\n",
    "\n",
    "While trying out parameters, make sure to take extensive notes and record the settings that you used in your various training runs.  In particular, you don't want to encounter a situation where you've trained a model for several hours but can't remember what settings you used :).\n",
    "\n",
    "### A Note on Tuning Hyperparameters\n",
    "\n",
    "To figure out how well your model is doing, you can look at how the training loss and perplexity evolve during training - and for the purposes of this project, you are encouraged to amend the hyperparameters based on this information.  \n",
    "\n",
    "However, this will not tell you if your model is overfitting to the training data, and, unfortunately, overfitting is a problem that is commonly encountered when training image captioning models.  \n",
    "\n",
    "For this project, you need not worry about overfitting. **This project does not have strict requirements regarding the performance of your model**, and you just need to demonstrate that your model has learned **_something_** when you generate captions on the test data.  For now, we strongly encourage you to train your model for the suggested 3 epochs without worrying about performance; then, you should immediately transition to the next notebook in the sequence (**3_Inference.ipynb**) to see how your model performs on the test data.  If your model needs to be changed, you can come back to this notebook, amend hyperparameters (if necessary), and re-train the model.\n",
    "\n",
    "That said, if you would like to go above and beyond in this project, you can read about some approaches to minimizing overfitting in section 4.3.1 of [this paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7505636).  In the next (optional) step of this notebook, we provide some guidance for assessing the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], Step [100/6471], Loss: 4.2143, Perplexity: 67.6462\n",
      "Epoch [1/6], Step [200/6471], Loss: 3.9183, Perplexity: 50.31327\n",
      "Epoch [1/6], Step [300/6471], Loss: 3.7629, Perplexity: 43.0748\n",
      "Epoch [1/6], Step [400/6471], Loss: 3.3978, Perplexity: 29.89835\n",
      "Epoch [1/6], Step [500/6471], Loss: 3.3678, Perplexity: 29.0156\n",
      "Epoch [1/6], Step [600/6471], Loss: 3.4265, Perplexity: 30.7701\n",
      "Epoch [1/6], Step [700/6471], Loss: 3.0022, Perplexity: 20.1300\n",
      "Epoch [1/6], Step [800/6471], Loss: 3.1205, Perplexity: 22.6580\n",
      "Epoch [1/6], Step [900/6471], Loss: 3.0781, Perplexity: 21.7162\n",
      "Epoch [1/6], Step [1000/6471], Loss: 3.1680, Perplexity: 23.7605\n",
      "Epoch [1/6], Step [1100/6471], Loss: 3.2166, Perplexity: 24.9431\n",
      "Epoch [1/6], Step [1200/6471], Loss: 2.9589, Perplexity: 19.2768\n",
      "Epoch [1/6], Step [1300/6471], Loss: 2.7101, Perplexity: 15.0313\n",
      "Epoch [1/6], Step [1400/6471], Loss: 2.6677, Perplexity: 14.4064\n",
      "Epoch [1/6], Step [1500/6471], Loss: 2.8028, Perplexity: 16.4904\n",
      "Epoch [1/6], Step [1600/6471], Loss: 3.3877, Perplexity: 29.59924\n",
      "Epoch [1/6], Step [1700/6471], Loss: 2.6917, Perplexity: 14.75621\n",
      "Epoch [1/6], Step [1800/6471], Loss: 2.5285, Perplexity: 12.5343\n",
      "Epoch [1/6], Step [1900/6471], Loss: 2.9842, Perplexity: 19.7715\n",
      "Epoch [1/6], Step [2000/6471], Loss: 2.5067, Perplexity: 12.2646\n",
      "Epoch [1/6], Step [2100/6471], Loss: 2.4967, Perplexity: 12.1423\n",
      "Epoch [1/6], Step [2200/6471], Loss: 2.4595, Perplexity: 11.6989\n",
      "Epoch [1/6], Step [2300/6471], Loss: 3.4935, Perplexity: 32.9013\n",
      "Epoch [1/6], Step [2400/6471], Loss: 2.4864, Perplexity: 12.0182\n",
      "Epoch [1/6], Step [2500/6471], Loss: 2.9866, Perplexity: 19.8181\n",
      "Epoch [1/6], Step [2600/6471], Loss: 2.4960, Perplexity: 12.1334\n",
      "Epoch [1/6], Step [2700/6471], Loss: 2.4461, Perplexity: 11.5430\n",
      "Epoch [1/6], Step [2800/6471], Loss: 2.6186, Perplexity: 13.7170\n",
      "Epoch [1/6], Step [2900/6471], Loss: 2.4173, Perplexity: 11.2155\n",
      "Epoch [1/6], Step [3000/6471], Loss: 2.3318, Perplexity: 10.2967\n",
      "Epoch [1/6], Step [3100/6471], Loss: 2.4982, Perplexity: 12.1605\n",
      "Epoch [1/6], Step [3200/6471], Loss: 2.4260, Perplexity: 11.3130\n",
      "Epoch [1/6], Step [3300/6471], Loss: 2.3185, Perplexity: 10.1603\n",
      "Epoch [1/6], Step [3400/6471], Loss: 2.3904, Perplexity: 10.9176\n",
      "Epoch [1/6], Step [3500/6471], Loss: 2.2319, Perplexity: 9.31772\n",
      "Epoch [1/6], Step [3600/6471], Loss: 2.7955, Perplexity: 16.3710\n",
      "Epoch [1/6], Step [3700/6471], Loss: 2.4361, Perplexity: 11.4288\n",
      "Epoch [1/6], Step [3800/6471], Loss: 2.3653, Perplexity: 10.6475\n",
      "Epoch [1/6], Step [3900/6471], Loss: 2.3188, Perplexity: 10.1635\n",
      "Epoch [1/6], Step [4000/6471], Loss: 2.6084, Perplexity: 13.5770\n",
      "Epoch [1/6], Step [4100/6471], Loss: 2.1731, Perplexity: 8.78554\n",
      "Epoch [1/6], Step [4200/6471], Loss: 2.3030, Perplexity: 10.0042\n",
      "Epoch [1/6], Step [4300/6471], Loss: 2.1524, Perplexity: 8.60599\n",
      "Epoch [1/6], Step [4400/6471], Loss: 2.1817, Perplexity: 8.86164\n",
      "Epoch [1/6], Step [4500/6471], Loss: 2.2797, Perplexity: 9.77403\n",
      "Epoch [1/6], Step [4600/6471], Loss: 2.2320, Perplexity: 9.31831\n",
      "Epoch [1/6], Step [4700/6471], Loss: 2.1986, Perplexity: 9.01213\n",
      "Epoch [1/6], Step [4800/6471], Loss: 2.3032, Perplexity: 10.0057\n",
      "Epoch [1/6], Step [4900/6471], Loss: 2.2768, Perplexity: 9.74555\n",
      "Epoch [1/6], Step [5000/6471], Loss: 2.1602, Perplexity: 8.67297\n",
      "Epoch [1/6], Step [5100/6471], Loss: 2.1281, Perplexity: 8.39878\n",
      "Epoch [1/6], Step [5200/6471], Loss: 2.1355, Perplexity: 8.460908\n",
      "Epoch [1/6], Step [5300/6471], Loss: 2.2706, Perplexity: 9.68545\n",
      "Epoch [1/6], Step [5400/6471], Loss: 2.0283, Perplexity: 7.60148\n",
      "Epoch [1/6], Step [5500/6471], Loss: 2.3526, Perplexity: 10.5133\n",
      "Epoch [1/6], Step [5600/6471], Loss: 2.1920, Perplexity: 8.95286\n",
      "Epoch [1/6], Step [5700/6471], Loss: 2.1451, Perplexity: 8.54314\n",
      "Epoch [1/6], Step [5800/6471], Loss: 2.3828, Perplexity: 10.8352\n",
      "Epoch [1/6], Step [5900/6471], Loss: 2.5995, Perplexity: 13.4566\n",
      "Epoch [1/6], Step [6000/6471], Loss: 2.3318, Perplexity: 10.2962\n",
      "Epoch [1/6], Step [6100/6471], Loss: 2.2945, Perplexity: 9.91982\n",
      "Epoch [1/6], Step [6200/6471], Loss: 1.9633, Perplexity: 7.122741\n",
      "Epoch [1/6], Step [6300/6471], Loss: 2.0049, Perplexity: 7.42521\n",
      "Epoch [1/6], Step [6400/6471], Loss: 2.2581, Perplexity: 9.56469\n",
      "Epoch [1/6], Step [6471/6471], Loss: 2.2966, Perplexity: 9.94046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 1/6 [2:35:33<12:57:45, 9333.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/6], Step [100/6471], Loss: 2.3440, Perplexity: 10.4231\n",
      "Epoch [2/6], Step [200/6471], Loss: 2.1892, Perplexity: 8.92807\n",
      "Epoch [2/6], Step [300/6471], Loss: 2.2794, Perplexity: 9.77113\n",
      "Epoch [2/6], Step [400/6471], Loss: 2.3258, Perplexity: 10.2352\n",
      "Epoch [2/6], Step [500/6471], Loss: 2.1826, Perplexity: 8.86961\n",
      "Epoch [2/6], Step [600/6471], Loss: 2.0607, Perplexity: 7.85179\n",
      "Epoch [2/6], Step [700/6471], Loss: 2.0086, Perplexity: 7.45272\n",
      "Epoch [2/6], Step [800/6471], Loss: 2.0653, Perplexity: 7.88789\n",
      "Epoch [2/6], Step [900/6471], Loss: 2.2495, Perplexity: 9.48348\n",
      "Epoch [2/6], Step [1000/6471], Loss: 2.3461, Perplexity: 10.4452\n",
      "Epoch [2/6], Step [1100/6471], Loss: 2.0561, Perplexity: 7.81520\n",
      "Epoch [2/6], Step [1200/6471], Loss: 2.1505, Perplexity: 8.58912\n",
      "Epoch [2/6], Step [1300/6471], Loss: 2.1978, Perplexity: 9.00501\n",
      "Epoch [2/6], Step [1400/6471], Loss: 2.3406, Perplexity: 10.3872\n",
      "Epoch [2/6], Step [1500/6471], Loss: 3.1429, Perplexity: 23.1704\n",
      "Epoch [2/6], Step [1600/6471], Loss: 2.6708, Perplexity: 14.4514\n",
      "Epoch [2/6], Step [1700/6471], Loss: 2.4155, Perplexity: 11.1953\n",
      "Epoch [2/6], Step [1800/6471], Loss: 2.2767, Perplexity: 9.74454\n",
      "Epoch [2/6], Step [1900/6471], Loss: 2.3338, Perplexity: 10.3175\n",
      "Epoch [2/6], Step [2000/6471], Loss: 2.3430, Perplexity: 10.4125\n",
      "Epoch [2/6], Step [2100/6471], Loss: 2.3285, Perplexity: 10.2621\n",
      "Epoch [2/6], Step [2200/6471], Loss: 2.0892, Perplexity: 8.07877\n",
      "Epoch [2/6], Step [2300/6471], Loss: 2.0572, Perplexity: 7.82401\n",
      "Epoch [2/6], Step [2400/6471], Loss: 2.1366, Perplexity: 8.47057\n",
      "Epoch [2/6], Step [2500/6471], Loss: 2.2071, Perplexity: 9.08960\n",
      "Epoch [2/6], Step [2600/6471], Loss: 2.2974, Perplexity: 9.94864\n",
      "Epoch [2/6], Step [2700/6471], Loss: 2.0649, Perplexity: 7.88465\n",
      "Epoch [2/6], Step [2800/6471], Loss: 1.8926, Perplexity: 6.63636\n",
      "Epoch [2/6], Step [2900/6471], Loss: 2.4264, Perplexity: 11.3181\n",
      "Epoch [2/6], Step [3000/6471], Loss: 2.1240, Perplexity: 8.36475\n",
      "Epoch [2/6], Step [3100/6471], Loss: 2.1004, Perplexity: 8.16901\n",
      "Epoch [2/6], Step [3200/6471], Loss: 2.2717, Perplexity: 9.69612\n",
      "Epoch [2/6], Step [3300/6471], Loss: 2.0617, Perplexity: 7.85916\n",
      "Epoch [2/6], Step [3400/6471], Loss: 2.1244, Perplexity: 8.36761\n",
      "Epoch [2/6], Step [3500/6471], Loss: 2.3248, Perplexity: 10.2243\n",
      "Epoch [2/6], Step [3600/6471], Loss: 1.9878, Perplexity: 7.29983\n",
      "Epoch [2/6], Step [3700/6471], Loss: 2.0693, Perplexity: 7.91944\n",
      "Epoch [2/6], Step [3800/6471], Loss: 1.9832, Perplexity: 7.26615\n",
      "Epoch [2/6], Step [3900/6471], Loss: 2.0384, Perplexity: 7.67831\n",
      "Epoch [2/6], Step [4000/6471], Loss: 2.7262, Perplexity: 15.2743\n",
      "Epoch [2/6], Step [4100/6471], Loss: 1.9647, Perplexity: 7.13272\n",
      "Epoch [2/6], Step [4200/6471], Loss: 2.3461, Perplexity: 10.4450\n",
      "Epoch [2/6], Step [4300/6471], Loss: 2.2632, Perplexity: 9.61396\n",
      "Epoch [2/6], Step [4400/6471], Loss: 2.3606, Perplexity: 10.5968\n",
      "Epoch [2/6], Step [4500/6471], Loss: 2.0613, Perplexity: 7.85610\n",
      "Epoch [2/6], Step [4600/6471], Loss: 2.1967, Perplexity: 8.99500\n",
      "Epoch [2/6], Step [4700/6471], Loss: 2.0105, Perplexity: 7.46716\n",
      "Epoch [2/6], Step [4800/6471], Loss: 1.9497, Perplexity: 7.02672\n",
      "Epoch [2/6], Step [4900/6471], Loss: 2.4209, Perplexity: 11.2564\n",
      "Epoch [2/6], Step [5000/6471], Loss: 2.1575, Perplexity: 8.64962\n",
      "Epoch [2/6], Step [5100/6471], Loss: 1.8962, Perplexity: 6.66044\n",
      "Epoch [2/6], Step [5200/6471], Loss: 2.2372, Perplexity: 9.36714\n",
      "Epoch [2/6], Step [5300/6471], Loss: 1.9512, Perplexity: 7.03700\n",
      "Epoch [2/6], Step [5400/6471], Loss: 2.0329, Perplexity: 7.63653\n",
      "Epoch [2/6], Step [5500/6471], Loss: 2.2122, Perplexity: 9.13591\n",
      "Epoch [2/6], Step [5600/6471], Loss: 2.1500, Perplexity: 8.58517\n",
      "Epoch [2/6], Step [5700/6471], Loss: 1.9122, Perplexity: 6.76811\n",
      "Epoch [2/6], Step [5800/6471], Loss: 1.9804, Perplexity: 7.24530\n",
      "Epoch [2/6], Step [5900/6471], Loss: 2.1276, Perplexity: 8.39436\n",
      "Epoch [2/6], Step [6000/6471], Loss: 2.0302, Perplexity: 7.61532\n",
      "Epoch [2/6], Step [6100/6471], Loss: 2.1879, Perplexity: 8.91656\n",
      "Epoch [2/6], Step [6200/6471], Loss: 2.0624, Perplexity: 7.86514\n",
      "Epoch [2/6], Step [6300/6471], Loss: 1.9324, Perplexity: 6.90594\n",
      "Epoch [2/6], Step [6400/6471], Loss: 1.9837, Perplexity: 7.26945\n",
      "Epoch [2/6], Step [6471/6471], Loss: 2.0684, Perplexity: 7.91238"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 2/6 [5:09:42<10:20:32, 9308.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/6], Step [100/6471], Loss: 2.0844, Perplexity: 8.0398\n",
      "Epoch [3/6], Step [200/6471], Loss: 2.2682, Perplexity: 9.66176\n",
      "Epoch [3/6], Step [300/6471], Loss: 1.9194, Perplexity: 6.81703\n",
      "Epoch [3/6], Step [400/6471], Loss: 2.0366, Perplexity: 7.66482\n",
      "Epoch [3/6], Step [500/6471], Loss: 2.2270, Perplexity: 9.27184\n",
      "Epoch [3/6], Step [600/6471], Loss: 2.1369, Perplexity: 8.47328\n",
      "Epoch [3/6], Step [700/6471], Loss: 1.9534, Perplexity: 7.05235\n",
      "Epoch [3/6], Step [800/6471], Loss: 2.1338, Perplexity: 8.44696\n",
      "Epoch [3/6], Step [900/6471], Loss: 2.4395, Perplexity: 11.4670\n",
      "Epoch [3/6], Step [1000/6471], Loss: 1.9573, Perplexity: 7.0802\n",
      "Epoch [3/6], Step [1100/6471], Loss: 2.1104, Perplexity: 8.25140\n",
      "Epoch [3/6], Step [1200/6471], Loss: 1.8576, Perplexity: 6.40861\n",
      "Epoch [3/6], Step [1300/6471], Loss: 2.2532, Perplexity: 9.51781\n",
      "Epoch [3/6], Step [1400/6471], Loss: 1.9819, Perplexity: 7.25654\n",
      "Epoch [3/6], Step [1500/6471], Loss: 2.1763, Perplexity: 8.81359\n",
      "Epoch [3/6], Step [1600/6471], Loss: 2.2276, Perplexity: 9.27714\n",
      "Epoch [3/6], Step [1700/6471], Loss: 2.0806, Perplexity: 8.00940\n",
      "Epoch [3/6], Step [1800/6471], Loss: 2.4720, Perplexity: 11.8461\n",
      "Epoch [3/6], Step [1900/6471], Loss: 2.1867, Perplexity: 8.90624\n",
      "Epoch [3/6], Step [2000/6471], Loss: 2.2525, Perplexity: 9.51111\n",
      "Epoch [3/6], Step [2100/6471], Loss: 1.9137, Perplexity: 6.77847\n",
      "Epoch [3/6], Step [2200/6471], Loss: 1.8863, Perplexity: 6.59493\n",
      "Epoch [3/6], Step [2300/6471], Loss: 2.1731, Perplexity: 8.78516\n",
      "Epoch [3/6], Step [2400/6471], Loss: 1.9256, Perplexity: 6.85913\n",
      "Epoch [3/6], Step [2500/6471], Loss: 2.1035, Perplexity: 8.19511\n",
      "Epoch [3/6], Step [2600/6471], Loss: 2.0178, Perplexity: 7.52150\n",
      "Epoch [3/6], Step [2700/6471], Loss: 2.3075, Perplexity: 10.0495\n",
      "Epoch [3/6], Step [2800/6471], Loss: 2.1552, Perplexity: 8.62960\n",
      "Epoch [3/6], Step [2900/6471], Loss: 2.1985, Perplexity: 9.01178\n",
      "Epoch [3/6], Step [3000/6471], Loss: 2.1835, Perplexity: 8.87738\n",
      "Epoch [3/6], Step [3100/6471], Loss: 1.9435, Perplexity: 6.98347\n",
      "Epoch [3/6], Step [3200/6471], Loss: 2.0271, Perplexity: 7.59213\n",
      "Epoch [3/6], Step [3300/6471], Loss: 1.9817, Perplexity: 7.25509\n",
      "Epoch [3/6], Step [3400/6471], Loss: 2.9509, Perplexity: 19.1238\n",
      "Epoch [3/6], Step [3500/6471], Loss: 2.0416, Perplexity: 7.70274\n",
      "Epoch [3/6], Step [3600/6471], Loss: 2.0056, Perplexity: 7.43074\n",
      "Epoch [3/6], Step [3700/6471], Loss: 1.9472, Perplexity: 7.00933\n",
      "Epoch [3/6], Step [3800/6471], Loss: 2.0806, Perplexity: 8.00950\n",
      "Epoch [3/6], Step [3900/6471], Loss: 2.0243, Perplexity: 7.57042\n",
      "Epoch [3/6], Step [4000/6471], Loss: 1.9758, Perplexity: 7.21256\n",
      "Epoch [3/6], Step [4100/6471], Loss: 1.8878, Perplexity: 6.60451\n",
      "Epoch [3/6], Step [4200/6471], Loss: 2.0177, Perplexity: 7.52134\n",
      "Epoch [3/6], Step [4300/6471], Loss: 2.1027, Perplexity: 8.18872\n",
      "Epoch [3/6], Step [4400/6471], Loss: 2.5647, Perplexity: 12.9969\n",
      "Epoch [3/6], Step [4500/6471], Loss: 2.1501, Perplexity: 8.58617\n",
      "Epoch [3/6], Step [4600/6471], Loss: 2.1469, Perplexity: 8.55863\n",
      "Epoch [3/6], Step [4700/6471], Loss: 2.0368, Perplexity: 7.66578\n",
      "Epoch [3/6], Step [4800/6471], Loss: 2.0752, Perplexity: 7.96588\n",
      "Epoch [3/6], Step [4900/6471], Loss: 1.9275, Perplexity: 6.87200\n",
      "Epoch [3/6], Step [5000/6471], Loss: 2.6005, Perplexity: 13.4702\n",
      "Epoch [3/6], Step [5100/6471], Loss: 2.0745, Perplexity: 7.96056\n",
      "Epoch [3/6], Step [5200/6471], Loss: 2.0350, Perplexity: 7.65231\n",
      "Epoch [3/6], Step [5300/6471], Loss: 1.9696, Perplexity: 7.16779\n",
      "Epoch [3/6], Step [5400/6471], Loss: 1.8612, Perplexity: 6.43169\n",
      "Epoch [3/6], Step [5500/6471], Loss: 1.9749, Perplexity: 7.20573\n",
      "Epoch [3/6], Step [5600/6471], Loss: 2.0064, Perplexity: 7.43681\n",
      "Epoch [3/6], Step [5700/6471], Loss: 2.0307, Perplexity: 7.61909\n",
      "Epoch [3/6], Step [5800/6471], Loss: 1.7809, Perplexity: 5.93490\n",
      "Epoch [3/6], Step [5900/6471], Loss: 2.1508, Perplexity: 8.59165\n",
      "Epoch [3/6], Step [6000/6471], Loss: 1.8907, Perplexity: 6.62404\n",
      "Epoch [3/6], Step [6100/6471], Loss: 2.0471, Perplexity: 7.74501\n",
      "Epoch [3/6], Step [6200/6471], Loss: 1.8721, Perplexity: 6.50202\n",
      "Epoch [3/6], Step [6300/6471], Loss: 2.2306, Perplexity: 9.30548\n",
      "Epoch [3/6], Step [6400/6471], Loss: 2.0906, Perplexity: 8.08984\n",
      "Epoch [3/6], Step [6471/6471], Loss: 1.8723, Perplexity: 6.50302"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 3/6 [7:43:23<7:44:05, 9281.93s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/6], Step [100/6471], Loss: 2.0039, Perplexity: 7.4183\n",
      "Epoch [4/6], Step [200/6471], Loss: 1.9627, Perplexity: 7.11895\n",
      "Epoch [4/6], Step [300/6471], Loss: 2.4022, Perplexity: 11.0474\n",
      "Epoch [4/6], Step [400/6471], Loss: 1.8442, Perplexity: 6.32291\n",
      "Epoch [4/6], Step [500/6471], Loss: 1.7641, Perplexity: 5.83649\n",
      "Epoch [4/6], Step [600/6471], Loss: 1.9732, Perplexity: 7.19341\n",
      "Epoch [4/6], Step [700/6471], Loss: 1.9385, Perplexity: 6.94835\n",
      "Epoch [4/6], Step [800/6471], Loss: 1.9524, Perplexity: 7.04578\n",
      "Epoch [4/6], Step [900/6471], Loss: 1.9851, Perplexity: 7.28015\n",
      "Epoch [4/6], Step [1000/6471], Loss: 1.9024, Perplexity: 6.7022\n",
      "Epoch [4/6], Step [1100/6471], Loss: 2.0508, Perplexity: 7.77388\n",
      "Epoch [4/6], Step [1200/6471], Loss: 2.1543, Perplexity: 8.62195\n",
      "Epoch [4/6], Step [1300/6471], Loss: 2.0065, Perplexity: 7.43692\n",
      "Epoch [4/6], Step [1400/6471], Loss: 2.2699, Perplexity: 9.67831\n",
      "Epoch [4/6], Step [1500/6471], Loss: 1.9461, Perplexity: 7.00102\n",
      "Epoch [4/6], Step [1600/6471], Loss: 2.0960, Perplexity: 8.13344\n",
      "Epoch [4/6], Step [1700/6471], Loss: 1.9847, Perplexity: 7.27653\n",
      "Epoch [4/6], Step [1800/6471], Loss: 2.0680, Perplexity: 7.90907\n",
      "Epoch [4/6], Step [1900/6471], Loss: 2.1672, Perplexity: 8.73417\n",
      "Epoch [4/6], Step [2000/6471], Loss: 1.8209, Perplexity: 6.17772\n",
      "Epoch [4/6], Step [2100/6471], Loss: 1.8524, Perplexity: 6.37486\n",
      "Epoch [4/6], Step [2200/6471], Loss: 2.0299, Perplexity: 7.61347\n",
      "Epoch [4/6], Step [2300/6471], Loss: 2.3975, Perplexity: 10.9961\n",
      "Epoch [4/6], Step [2400/6471], Loss: 2.3054, Perplexity: 10.0284\n",
      "Epoch [4/6], Step [2500/6471], Loss: 2.1813, Perplexity: 8.85819\n",
      "Epoch [4/6], Step [2600/6471], Loss: 1.9583, Perplexity: 7.08762\n",
      "Epoch [4/6], Step [2700/6471], Loss: 2.1587, Perplexity: 8.65984\n",
      "Epoch [4/6], Step [2800/6471], Loss: 2.0016, Perplexity: 7.40080\n",
      "Epoch [4/6], Step [2900/6471], Loss: 1.9762, Perplexity: 7.21560\n",
      "Epoch [4/6], Step [3000/6471], Loss: 1.8621, Perplexity: 6.43752\n",
      "Epoch [4/6], Step [3100/6471], Loss: 1.7765, Perplexity: 5.90923\n",
      "Epoch [4/6], Step [3200/6471], Loss: 1.8695, Perplexity: 6.48533\n",
      "Epoch [4/6], Step [3300/6471], Loss: 2.2021, Perplexity: 9.04391\n",
      "Epoch [4/6], Step [3400/6471], Loss: 1.9688, Perplexity: 7.16224\n",
      "Epoch [4/6], Step [3500/6471], Loss: 2.0449, Perplexity: 7.72872\n",
      "Epoch [4/6], Step [3600/6471], Loss: 1.8806, Perplexity: 6.55754\n",
      "Epoch [4/6], Step [3700/6471], Loss: 1.9880, Perplexity: 7.30125\n",
      "Epoch [4/6], Step [3800/6471], Loss: 2.0142, Perplexity: 7.49486\n",
      "Epoch [4/6], Step [3900/6471], Loss: 1.8179, Perplexity: 6.15905\n",
      "Epoch [4/6], Step [4000/6471], Loss: 1.8799, Perplexity: 6.55307\n",
      "Epoch [4/6], Step [4100/6471], Loss: 1.9013, Perplexity: 6.69437\n",
      "Epoch [4/6], Step [4200/6471], Loss: 1.7666, Perplexity: 5.85077\n",
      "Epoch [4/6], Step [4300/6471], Loss: 2.5971, Perplexity: 13.4254\n",
      "Epoch [4/6], Step [4400/6471], Loss: 2.0727, Perplexity: 7.94662\n",
      "Epoch [4/6], Step [4500/6471], Loss: 2.0164, Perplexity: 7.51162\n",
      "Epoch [4/6], Step [4600/6471], Loss: 1.9606, Perplexity: 7.10366\n",
      "Epoch [4/6], Step [4700/6471], Loss: 1.8295, Perplexity: 6.23090\n",
      "Epoch [4/6], Step [4800/6471], Loss: 1.9517, Perplexity: 7.04073\n",
      "Epoch [4/6], Step [4900/6471], Loss: 1.9265, Perplexity: 6.86585\n",
      "Epoch [4/6], Step [5000/6471], Loss: 1.8942, Perplexity: 6.64735\n",
      "Epoch [4/6], Step [5100/6471], Loss: 2.1495, Perplexity: 8.58090\n",
      "Epoch [4/6], Step [5200/6471], Loss: 1.9397, Perplexity: 6.95658\n",
      "Epoch [4/6], Step [5300/6471], Loss: 1.9001, Perplexity: 6.68662\n",
      "Epoch [4/6], Step [5400/6471], Loss: 1.9382, Perplexity: 6.94607\n",
      "Epoch [4/6], Step [5500/6471], Loss: 1.8980, Perplexity: 6.67270\n",
      "Epoch [4/6], Step [5600/6471], Loss: 1.7390, Perplexity: 5.69194\n",
      "Epoch [4/6], Step [5700/6471], Loss: 1.9290, Perplexity: 6.88308\n",
      "Epoch [4/6], Step [5800/6471], Loss: 1.8678, Perplexity: 6.47382\n",
      "Epoch [4/6], Step [5900/6471], Loss: 2.2217, Perplexity: 9.22302\n",
      "Epoch [4/6], Step [6000/6471], Loss: 2.0257, Perplexity: 7.58157\n",
      "Epoch [4/6], Step [6100/6471], Loss: 2.8890, Perplexity: 17.9758\n",
      "Epoch [4/6], Step [6200/6471], Loss: 1.9677, Perplexity: 7.15448\n",
      "Epoch [4/6], Step [6300/6471], Loss: 2.0666, Perplexity: 7.89781\n",
      "Epoch [4/6], Step [6400/6471], Loss: 1.9797, Perplexity: 7.24060\n",
      "Epoch [4/6], Step [6471/6471], Loss: 1.8036, Perplexity: 6.07160"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 4/6 [10:17:44<5:09:11, 9275.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/6], Step [100/6471], Loss: 1.9239, Perplexity: 6.8477\n",
      "Epoch [5/6], Step [200/6471], Loss: 1.7737, Perplexity: 5.89277\n",
      "Epoch [5/6], Step [300/6471], Loss: 1.7721, Perplexity: 5.88300\n",
      "Epoch [5/6], Step [400/6471], Loss: 1.9871, Perplexity: 7.29429\n",
      "Epoch [5/6], Step [500/6471], Loss: 1.9421, Perplexity: 6.97337\n",
      "Epoch [5/6], Step [600/6471], Loss: 1.9134, Perplexity: 6.77584\n",
      "Epoch [5/6], Step [700/6471], Loss: 1.8100, Perplexity: 6.11051\n",
      "Epoch [5/6], Step [800/6471], Loss: 1.8607, Perplexity: 6.42853\n",
      "Epoch [5/6], Step [900/6471], Loss: 2.0545, Perplexity: 7.80289\n",
      "Epoch [5/6], Step [949/6471], Loss: 1.9866, Perplexity: 7.29064"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-676fde330744>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Obtain the batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Move batch of images and captions to GPU if CUDA is available.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/workspace/data_loader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;31m# Convert image to tensor and pre-process using transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    890\u001b[0m         \"\"\"\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "old_time = time.time()\n",
    "response = requests.request(\"GET\", \n",
    "                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "                            headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "for epoch in tqdm(range(1, num_epochs+1)):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        if time.time() - old_time > 60:\n",
    "            old_time = time.time()\n",
    "            requests.request(\"POST\", \n",
    "                             \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "                             headers={'Authorization': \"STAR \" + response.text})\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interrupt the kernel after 4 epochs to see how good the model is performing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: (Optional) Validate your Model\n",
    "\n",
    "To assess potential overfitting, one approach is to assess performance on a validation set.  If you decide to do this **optional** task, you are required to first complete all of the steps in the next notebook in the sequence (**3_Inference.ipynb**); as part of that notebook, you will write and test code (specifically, the `sample` method in the `DecoderRNN` class) that uses your RNN decoder to generate captions.  That code will prove incredibly useful here. \n",
    "\n",
    "If you decide to validate your model, please do not edit the data loader in **data_loader.py**.  Instead, create a new file named **data_loader_val.py** containing the code for obtaining the data loader for the validation data.  You can access:\n",
    "- the validation images at filepath `'/opt/cocoapi/images/train2014/'`, and\n",
    "- the validation image caption annotation file at filepath `'/opt/cocoapi/annotations/captions_val2014.json'`.\n",
    "\n",
    "The suggested approach to validating your model involves creating a json file such as [this one](https://github.com/cocodataset/cocoapi/blob/master/results/captions_val2014_fakecap_results.json) containing your model's predicted captions for the validation images.  Then, you can write your own script or use one that you [find online](https://github.com/tylin/coco-caption) to calculate the BLEU score of your model.  You can read more about the BLEU score, along with other evaluation metrics (such as TEOR and Cider) in section 4.1 of [this paper](https://arxiv.org/pdf/1411.4555.pdf).  For more information about how to use the annotation file, check out the [website](http://cocodataset.org/#download) for the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) TODO: Validate your model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
